# How To Use NNCASE(V0.2.0 Beta4)

.\ncc.exe compile Model_V0_1.tflite Model_V0_1.kmodel -i tflite -o kmodel --dataset ./data/JPEGImages_Sample/ --dataset-format image --inference-type uint8 --input-mean 0 --input-std 1 --dump-ir --input-type uint8 --max-allocator-solve-secs 120 --calibrate-method l2 --dump-weights-range --weights-quantize-threshold 32  --output-quantize-threshold 1024
1. Import graph...
2. Optimize Pass 1...
Dump weights range ...
Conv2D_0{-7.69981, 5.65006}
Conv2D_3{-1.20796, 1.27813}
Conv2D_4{-0.778667, 0.827375}
Conv2D_5{-2.01471, 1.77771}
Conv2D_6{-0.421971, 0.841585}
Conv2D_7{-0.719524, 0.5067}
Conv2D_12{-0.604414, 0.764012}
Conv2D_13{-0.690024, 0.857043}
Conv2D_14{-1.06358, 1.38815}
Conv2D_15{-1.23217, 1.54182}
Conv2D_16{-0.545631, 0.547883}
Conv2D_17{-2.25043, 0.942201}
Conv2D_18{-0.412925, 0.524094}
Conv2D_21{-0.659724, 0.648631}
Conv2D_22{-0.897048, 0.812928}
Conv2D_23{-0.413057, 0.535818}
Conv2D_24{-0.74034, 0.598373}
Conv2D_27{-0.587591, 0.627704}
Conv2D_28{-0.83368, 0.817675}
Conv2D_29{-0.471071, 0.345599}
Conv2D_30{-0.455182, 0.429017}
Conv2D_31{-0.450613, 0.443387}
Conv2D_36{-0.631094, 0.615425}
Conv2D_37{-0.716845, 0.864594}
Conv2D_38{-0.731777, 0.872114}
Conv2D_39{-0.864499, 1.04279}
Conv2D_40{-0.321136, 0.294978}
Conv2D_41{-0.389408, 0.618573}
Conv2D_42{-0.463768, 0.434249}
Conv2D_45{-0.628029, 0.606052}
Conv2D_46{-0.857071, 0.743852}
Conv2D_47{-0.326795, 0.319491}
Conv2D_48{-0.34, 0.583243}
Conv2D_51{-0.639259, 0.782657}
Conv2D_52{-0.792057, 0.785551}
Conv2D_53{-0.375116, 0.291687}
Conv2D_54{-0.428019, 0.417399}
Conv2D_57{-0.864689, 0.800644}
Conv2D_58{-1.12123, 0.860939}
Conv2D_59{-0.416292, 0.347888}
Conv2D_60{-0.357286, 0.383075}
Conv2D_63{-0.967548, 0.958137}
Conv2D_64{-1.25436, 1.52667}
Conv2D_65{-0.290778, 0.240788}
Conv2D_66{-0.576748, 0.549428}
Conv2D_69{-0.59016, 1.03322}
Conv2D_70{-1.12056, 0.968841}
Conv2D_71{-0.612557, 0.491848}
Conv2D_72{-1.0838, 0.808319}
Conv2D_75{-1.17118, 1.54664}
Conv2D_76{-2.04342, 7.5335}
Conv2D_77{-0.703412, 0.894966}
Conv2D_78{-1.09949, 0.698665}
Conv2D_81{-1.68518, 2.37004}
Conv2D_82{-0.987302, 1.36442}
Conv2D_83{-0.821405, 0.529464}
Conv2D_84{-1.40452, 0.955955}
Conv2D_87{9.63886, 9.63886}
Conv2D_88{-2.16083, 1.17549e-38}
Conv2D_89{-9.00428, 4.28854}
Conv2D_1{-2.07445, 2.97643}
Conv2D_2{-0.814324, 2.10761}
Conv2D_8{-1.70549, 1.33728}
Conv2D_9{-1.00268, 1.23354}
Conv2D_19{-1.24083, 1.69613}
Conv2D_20{-0.968029, 1.10703}
Conv2D_25{-1.57136, 1.99744}
Conv2D_26{-1.276, 1.15703}
Conv2D_32{-2.44768, 2.68878}
Conv2D_33{-1.91571, 2.17723}
Conv2D_43{-1.63416, 6.87644}
Conv2D_44{-2.39985, 2.38712}
Conv2D_49{-4.55612, 9.03819}
Conv2D_50{-5.61178, 20.7805}
Conv2D_55{-2.23221, 2.68983}
Conv2D_56{-1.31554, 1.76325}
Conv2D_61{-2.53103, 10.576}
Conv2D_62{-9.62121, 9.81594}
Conv2D_34{-1.33452, 1.98011}
Conv2D_35{-1.18227, 1.51693}
Conv2D_67{-12.4833, 18.4161}
Conv2D_68{-6.76074, 6.29711}
Conv2D_73{-15.2925, 25.2836}
Conv2D_74{-33.6843, 27.6947}
Conv2D_10{-1.87758, 1.64303}
Conv2D_11{-0.869822, 1.2687}
Conv2D_79{-1.52001, 2.16186}
Conv2D_80{-1.46659, 2.8314}
Conv2D_85{0.00839139, 0.0886092}
Conv2D_86{-0.0923645, 0.481875}
3. Optimize Pass 2...
4. Quantize...
  4.1. Add quantization checkpoints...
  4.2. Get activation ranges...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.841s
  4.3. Get activation distributions...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.537s
  4.4. Find optimal thresholds...
{0, 6.49012} -> {0, 6.23026}                         ] 0% 0s
{0, 6.85896} -> {0, 5.97815}                         ] 0% 0.096s
{0, 7.42506} -> {0, 7.21116}                         ] 1% 0.192s
{0, 6.42045} -> {0, 6.12889}                         ] 2% 0.287s
{0, 6.6166} -> {0, 6.25152}                          ] 3% 0.396s
{0, 7.94185} -> {0, 6.92198}                         ] 4% 0.49s
{0, 12.5055} -> {0, 11.4674}                         ] 5% 0.586s
{0, 7.94185} -> {0, 7.22833}                         ] 6% 0.678s
{0, 4.86935} -> {0, 4.24404}                         ] 7% 0.777s
{0, 6.85896} -> {0, 6.20589}                         ] 7% 0.873s
{0, 7.96055} -> {0, 7.52521}                         ] 8% 0.969s
{0, 6.80435} -> {0, 6.3525}                          ] 9% 1.065s
{0, 8.48414} -> {0, 7.92488}                         ] 10% 1.16s
{0, 9.10347} -> {0, 8.41004}                         ] 11% 1.258s
{0, 7.77231} -> {0, 7.57117}                         ] 12% 1.357s
{0, 5.14937} -> {0, 4.64901}                         ] 13% 1.468s
{0, 8.03881} -> {0, 7.00649}                         ] 14% 1.564s
{0, 4.87661} -> {0, 4.68611}                         ] 15% 1.661s
{0, 7.94185} -> {0, 6.92198}                         ] 15% 1.757s
{0, 8.101} -> {0, 7.06069}                           ] 16% 1.849s
{0, 7.62972} -> {0, 6.64993}                         ] 17% 1.948s
{0, 7.62872} -> {0, 6.64906}                         ] 18% 2.041s
{0, 7.69642} -> {0, 7.26425}                         ] 19% 2.133s
{0, 8.21379} -> {0, 7.81273}                         ] 20% 2.227s
{0, 6.45081} -> {0, 6.45081}                         ] 21% 2.335s
{0, 5.15102} -> {0, 4.70835}                         ] 22% 2.435s
{0, 7.70094} -> {0, 7.63325}                         ] 23% 2.539s
{0, 6.23602} -> {0, 5.63007}                         ] 23% 2.633s
{0, 6.82579} -> {0, 6.63581}                         ] 24% 2.727s
{0, 5.53839} -> {0, 5.26255}                         ] 25% 2.822s
{0, 8.101} -> {0, 7.06069}                           ] 26% 2.917s
{0, 7.58859} -> {0, 7.27734}                         ] 27% 3.012s
{0, 11.5465} -> {0, 11.0221}                         ] 28% 3.107s
{0, 8.74409} -> {0, 7.62119}                         ] 29% 3.201s
{0, 6.23602} -> {0, 5.63007}                         ] 30% 3.342s
{0, 9.56657} -> {0, 8.93129}                         ] 30% 3.439s
{0, 10.8683} -> {0, 9.4726}                          ] 31% 3.548s
{0, 8.21897} -> {0, 7.79357}                         ] 32% 3.645s
{0, 6.5187} -> {0, 5.98078}                          ] 33% 3.743s
{0, 9.41811} -> {0, 9.20197}                         ] 34% 3.838s
{0, 7.43552} -> {0, 6.66946}                         ] 35% 3.933s
{0, 6.31197} -> {0, 5.5014}                          ] 36% 4.028s
{0, 8.74409} -> {0, 6.89536}                         ] 37% 4.125s
{0, 6.23602} -> {0, 5.4352}                          ] 38% 4.218s
{0, 6.67726} -> {0, 6.55663}                         ] 38% 4.314s
{0, 9.40854} -> {0, 9.02724}                         ] 39% 4.413s
{0, 4.8006} -> {0, 4.69746}                          ] 40% 4.507s
{0, 8.03881} -> {0, 7.77583}                         ] 41% 4.62s
{0, 9.41811} -> {0, 9.20197}                         ] 42% 4.711s
{0, 7.14744} -> {0, 6.89617}                         ] 43% 4.808s
{0, 10.7851} -> {0, 10.4744}                         ] 44% 4.901s
{0, 6.02894} -> {0, 5.81699}                         ] 45% 4.995s
{0, 6.23602} -> {0, 5.63007}                         ] 46% 5.09s
{0, 5.18716} -> {0, 4.92628}                         ] 46% 5.183s
{0, 7.76536} -> {0, 7.58715}                         ] 47% 5.277s
{0, 6.24038} -> {0, 6.02099}                         ] 48% 5.383s
{0, 11.2678} -> {0, 11.1578}                         ] 49% 5.48s
{0, 8.43533} -> {0, 7.71042}>                        ] 50% 5.578s
{0, 11.6405} -> {0, 11.1119}>                        ] 51% 5.683s
{0, 9.15786} -> {0, 8.742}===>                       ] 52% 5.778s
{0, 7.46627} -> {0, 7.12723}=>                       ] 53% 5.877s
{0, 6.67027} -> {0, 6.39017}=>                       ] 53% 5.971s
{0, 8.43533} -> {0, 7.35209}==>                      ] 54% 6.066s
{0, 9.22257} -> {0, 8.80377}==>                      ] 55% 6.159s
{0, 6.7725} -> {0, 6.58732}====>                     ] 56% 6.251s
{0, 8.21379} -> {0, 7.15899}===>                     ] 57% 6.349s
{0, 5.34708} -> {0, 5.10427}====>                    ] 58% 6.448s
{0, 7.17185} -> {0, 7.05629}====>                    ] 59% 6.542s
{0, 7.76536} -> {0, 7.04494}=====>                   ] 60% 6.645s
{0, 5.99011} -> {0, 5.84972}=====>                   ] 61% 6.742s
{0, 5.61846} -> {0, 5.30846}=====>                   ] 61% 6.836s
{0, 7.98408} -> {0, 7.73848}======>                  ] 62% 6.935s
{0, 9.41811} -> {0, 9.03182}======>                  ] 63% 7.032s
{0, 9.17409} -> {0, 8.96356}=======>                 ] 64% 7.129s
{0, 6.38295} -> {0, 6.27698}=======>                 ] 65% 7.273s
{0, 4.14825} -> {0, 4.14825}========>                ] 66% 7.374s
{0, 8.90911} -> {0, 8.64375}========>                ] 67% 7.468s
{0, 8.90911} -> {0, 7.76502}=========>               ] 68% 7.561s
{0, 5.08739} -> {0, 4.93089}=========>               ] 69% 7.661s
{0, 5.61846} -> {0, 5.13288}=========>               ] 69% 7.767s
{0, 7.78294} -> {0, 7.57773}==========>              ] 70% 7.862s
{0, 9.01326} -> {0, 8.78881}==========>              ] 71% 7.954s
{0, 4.93296} -> {0, 4.92333}===========>             ] 72% 8.049s
{0, 6.70045} -> {0, 6.6252}============>             ] 73% 8.145s
{0, 5.81036} -> {0, 5.6146}=============>            ] 74% 8.248s
{0, 6.6802} -> {0, 6.10286}=============>            ] 75% 8.344s
{0, 5.81036} -> {0, 5.2855}==============>           ] 76% 8.439s
{0, 5.05064} -> {0, 4.80156}=============>           ] 76% 8.533s
{0, 5.05064} -> {0, 4.80156}=============>           ] 77% 8.631s
{0, 10.5383} -> {0, 10.4045}==============>          ] 78% 8.743s
{0, 7.19098} -> {0, 6.93817}==============>          ] 79% 8.838s
{0, 5.47594} -> {0, 5.31284}===============>         ] 80% 8.936s
{0, 5.54847} -> {0, 5.47532}===============>         ] 81% 9.031s
{0, 8.95441} -> {0, 8.70081}================>        ] 82% 9.128s
{0, 8.95441} -> {0, 8.198}==================>        ] 83% 9.225s
{0, 5.52642} -> {0, 5.09197}=================>       ] 84% 9.318s
{0, 7.94185} -> {0, 7.22833}=================>       ] 84% 9.415s
{0, 5.18016} -> {0, 4.83616}=================>       ] 85% 9.512s
{0, 5.58032} -> {0, 5.5231}===================>      ] 86% 9.606s
{0, 5.11194} -> {0, 4.97715}==================>      ] 87% 9.702s
{0, 7.94185} -> {0, 7.10036}===================>     ] 88% 9.812s
{0, 2.93711} -> {0, 2.7435}====================>     ] 89% 9.906s
{0, 5.52642} -> {0, 4.98943}====================>    ] 90% 10.003s
{0, 5.42753} -> {0, 5.30297}====================>    ] 91% 10.098s
{0, 9.68039} -> {0, 9.47241}=====================>   ] 92% 10.194s
{0, 10.4949} -> {0, 10.167}======================>   ] 92% 10.294s
{0, 6.69615} -> {0, 6.56536}=====================>   ] 93% 10.389s
{0, 9.68039} -> {0, 8.43725}======================>  ] 94% 10.487s
{0, 0.0673623} -> {0, 0.0673623}==================>  ] 95% 10.584s
{0, 0.01} -> {0, 0.01}=============================> ] 96% 10.681s
{0, 2.28979} -> {0, 2.24283}=======================> ] 97% 10.777s
{0, 3.03497} -> {0, 2.9505}=========================>] 98% 10.886s
{-55.297, 53.387} -> {-51.2107, 50.7867}============>] 99% 10.981s
  [==================================================] 100% 64.417s
  4.5. Quantize graph...
WARN: Conv2D_2 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_9 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_20 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_26 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_33 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_44 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_50 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_56 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_62 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_35 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_68 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_73 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_74 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_11 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_80 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_86 Fallback to float conv2d due to weights divergence.
5. Lowering...
6. Optimize Pass 3...
7. Generate code...
  Plan buffers...
  Emit code...
Working memory usage: 353280 B

SUMMARY
INPUTS
0       input_1 1x3x32x32
OUTPUTS
0       Identity        1x5x32x32

.\ncc.exe compile Model_V0_1.tflite Model_V0_1.kmodel -i tflite -o kmodel --dataset ./data/JPEGImages_Sample/ --dataset-format image --inference-type uint8 --input-mean 0 --input-std 1 --dump-ir --input-type uint8 --max-allocator-solve-secs 120 --calibrate-method l2 --dump-weights-range --weights-quantize-threshold 1024  --output-quantize-threshold 1024
1. Import graph...
2. Optimize Pass 1...
Dump weights range ...
Conv2D_0{-7.69981, 5.65006}
Conv2D_3{-1.20796, 1.27813}
Conv2D_4{-0.778667, 0.827375}
Conv2D_5{-2.01471, 1.77771}
Conv2D_6{-0.421971, 0.841585}
Conv2D_7{-0.719524, 0.5067}
Conv2D_12{-0.604414, 0.764012}
Conv2D_13{-0.690024, 0.857043}
Conv2D_14{-1.06358, 1.38815}
Conv2D_15{-1.23217, 1.54182}
Conv2D_16{-0.545631, 0.547883}
Conv2D_17{-2.25043, 0.942201}
Conv2D_18{-0.412925, 0.524094}
Conv2D_21{-0.659724, 0.648631}
Conv2D_22{-0.897048, 0.812928}
Conv2D_23{-0.413057, 0.535818}
Conv2D_24{-0.74034, 0.598373}
Conv2D_27{-0.587591, 0.627704}
Conv2D_28{-0.83368, 0.817675}
Conv2D_29{-0.471071, 0.345599}
Conv2D_30{-0.455182, 0.429017}
Conv2D_31{-0.450613, 0.443387}
Conv2D_36{-0.631094, 0.615425}
Conv2D_37{-0.716845, 0.864594}
Conv2D_38{-0.731777, 0.872114}
Conv2D_39{-0.864499, 1.04279}
Conv2D_40{-0.321136, 0.294978}
Conv2D_41{-0.389408, 0.618573}
Conv2D_42{-0.463768, 0.434249}
Conv2D_45{-0.628029, 0.606052}
Conv2D_46{-0.857071, 0.743852}
Conv2D_47{-0.326795, 0.319491}
Conv2D_48{-0.34, 0.583243}
Conv2D_51{-0.639259, 0.782657}
Conv2D_52{-0.792057, 0.785551}
Conv2D_53{-0.375116, 0.291687}
Conv2D_54{-0.428019, 0.417399}
Conv2D_57{-0.864689, 0.800644}
Conv2D_58{-1.12123, 0.860939}
Conv2D_59{-0.416292, 0.347888}
Conv2D_60{-0.357286, 0.383075}
Conv2D_63{-0.967548, 0.958137}
Conv2D_64{-1.25436, 1.52667}
Conv2D_65{-0.290778, 0.240788}
Conv2D_66{-0.576748, 0.549428}
Conv2D_69{-0.59016, 1.03322}
Conv2D_70{-1.12056, 0.968841}
Conv2D_71{-0.612557, 0.491848}
Conv2D_72{-1.0838, 0.808319}
Conv2D_75{-1.17118, 1.54664}
Conv2D_76{-2.04342, 7.5335}
Conv2D_77{-0.703412, 0.894966}
Conv2D_78{-1.09949, 0.698665}
Conv2D_81{-1.68518, 2.37004}
Conv2D_82{-0.987302, 1.36442}
Conv2D_83{-0.821405, 0.529464}
Conv2D_84{-1.40452, 0.955955}
Conv2D_87{9.63886, 9.63886}
Conv2D_88{-2.16083, 1.17549e-38}
Conv2D_89{-9.00428, 4.28854}
Conv2D_1{-2.07445, 2.97643}
Conv2D_2{-0.814324, 2.10761}
Conv2D_8{-1.70549, 1.33728}
Conv2D_9{-1.00268, 1.23354}
Conv2D_19{-1.24083, 1.69613}
Conv2D_20{-0.968029, 1.10703}
Conv2D_25{-1.57136, 1.99744}
Conv2D_26{-1.276, 1.15703}
Conv2D_32{-2.44768, 2.68878}
Conv2D_33{-1.91571, 2.17723}
Conv2D_43{-1.63416, 6.87644}
Conv2D_44{-2.39985, 2.38712}
Conv2D_49{-4.55612, 9.03819}
Conv2D_50{-5.61178, 20.7805}
Conv2D_55{-2.23221, 2.68983}
Conv2D_56{-1.31554, 1.76325}
Conv2D_61{-2.53103, 10.576}
Conv2D_62{-9.62121, 9.81594}
Conv2D_34{-1.33452, 1.98011}
Conv2D_35{-1.18227, 1.51693}
Conv2D_67{-12.4833, 18.4161}
Conv2D_68{-6.76074, 6.29711}
Conv2D_73{-15.2925, 25.2836}
Conv2D_74{-33.6843, 27.6947}
Conv2D_10{-1.87758, 1.64303}
Conv2D_11{-0.869822, 1.2687}
Conv2D_79{-1.52001, 2.16186}
Conv2D_80{-1.46659, 2.8314}
Conv2D_85{0.00839139, 0.0886092}
Conv2D_86{-0.0923645, 0.481875}
3. Optimize Pass 2...
4. Quantize...
  4.1. Add quantization checkpoints...
  4.2. Get activation ranges...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.842s
  4.3. Get activation distributions...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.483s
  4.4. Find optimal thresholds...
{0, 4.86935} -> {0, 4.24404}                         ] 0% 0s
{0, 7.19098} -> {0, 6.93817}                         ] 0% 0.095s
{0, 8.21379} -> {0, 7.15899}                         ] 1% 0.19s
{0, 6.85896} -> {0, 5.97815}                         ] 2% 0.285s
{0, 7.96055} -> {0, 7.52521}                         ] 3% 0.382s
{0, 7.17185} -> {0, 7.05629}                         ] 4% 0.477s
{0, 12.5055} -> {0, 11.4674}                         ] 5% 0.57s
{0, 7.94185} -> {0, 7.22833}                         ] 6% 0.663s
{0, 6.80435} -> {0, 6.3525}                          ] 7% 0.758s
{0, 6.02894} -> {0, 5.81699}                         ] 7% 0.853s
{0, 6.85896} -> {0, 6.20589}                         ] 8% 0.951s
{0, 7.94185} -> {0, 6.92198}                         ] 9% 1.058s
{0, 5.34708} -> {0, 5.10427}                         ] 10% 1.151s
{0, 8.48414} -> {0, 7.92488}                         ] 11% 1.245s
{0, 6.6166} -> {0, 6.25152}                          ] 12% 1.341s
{0, 9.10347} -> {0, 8.41004}                         ] 13% 1.433s
{0, 7.94185} -> {0, 6.92198}                         ] 14% 1.53s
{0, 10.8683} -> {0, 9.4726}                          ] 15% 1.627s
{0, 7.43552} -> {0, 6.66946}                         ] 15% 1.723s
{0, 5.14937} -> {0, 4.64901}                         ] 16% 1.815s
{0, 11.6405} -> {0, 11.1119}                         ] 17% 1.91s
{0, 4.87661} -> {0, 4.68611}                         ] 18% 2.016s
{0, 6.45081} -> {0, 6.45081}                         ] 19% 2.111s
{0, 8.101} -> {0, 7.06069}                           ] 20% 2.208s
{0, 7.62972} -> {0, 6.64993}                         ] 21% 2.303s
{0, 8.43533} -> {0, 7.71042}                         ] 22% 2.409s
{0, 7.69642} -> {0, 7.26425}                         ] 23% 2.505s
{0, 9.22257} -> {0, 8.80377}                         ] 23% 2.6s
{0, 5.15102} -> {0, 4.70835}                         ] 24% 2.696s
{0, 6.23602} -> {0, 5.4352}                          ] 25% 2.825s
{0, 6.82579} -> {0, 6.63581}                         ] 26% 2.918s
{0, 6.49012} -> {0, 6.23026}                         ] 27% 3.01s
{0, 5.42753} -> {0, 5.30297}                         ] 28% 3.12s
{0, 5.53839} -> {0, 5.26255}                         ] 29% 3.213s
{0, 8.101} -> {0, 7.06069}                           ] 30% 3.319s
{0, 8.74409} -> {0, 7.62119}                         ] 30% 3.414s
{0, 7.76536} -> {0, 7.58715}                         ] 31% 3.51s
{0, 8.74409} -> {0, 6.89536}                         ] 32% 3.602s
{0, 9.56657} -> {0, 8.93129}                         ] 33% 3.699s
{0, 6.24038} -> {0, 6.02099}                         ] 34% 3.793s
{0, 9.40854} -> {0, 9.02724}                         ] 35% 3.887s
{0, 6.5187} -> {0, 5.98078}                          ] 36% 3.982s
{0, 7.46627} -> {0, 7.12723}                         ] 37% 4.082s
{0, 6.31197} -> {0, 5.5014}                          ] 38% 4.189s
{0, 7.42506} -> {0, 7.21116}                         ] 38% 4.285s
{0, 6.23602} -> {0, 5.63007}                         ] 39% 4.382s
{0, 6.67726} -> {0, 6.55663}                         ] 40% 4.478s
{0, 8.03881} -> {0, 7.00649}                         ] 41% 4.573s
{0, 7.58859} -> {0, 7.27734}                         ] 42% 4.666s
{0, 4.8006} -> {0, 4.69746}                          ] 43% 4.763s
{0, 7.14744} -> {0, 6.89617}                         ] 44% 4.855s
{0, 11.2678} -> {0, 11.1578}                         ] 45% 4.949s
{0, 6.23602} -> {0, 5.63007}                         ] 46% 5.047s
{0, 8.03881} -> {0, 7.77583}                         ] 46% 5.149s
{0, 6.42045} -> {0, 6.12889}                         ] 47% 5.25s
{0, 7.77231} -> {0, 7.57117}                         ] 48% 5.351s
{0, 7.98408} -> {0, 7.73848}                         ] 49% 5.446s
{0, 8.21897} -> {0, 7.79357}>                        ] 50% 5.541s
{0, 5.99011} -> {0, 5.84972}>                        ] 51% 5.637s
{0, 11.5465} -> {0, 11.0221}=>                       ] 52% 5.732s
{0, 9.15786} -> {0, 8.742}===>                       ] 53% 5.825s
{0, 10.7851} -> {0, 10.4744}=>                       ] 53% 5.918s
{0, 6.67027} -> {0, 6.39017}==>                      ] 54% 6.053s
{0, 8.43533} -> {0, 7.35209}==>                      ] 55% 6.269s
{0, 7.62872} -> {0, 6.64906}===>                     ] 56% 6.406s
{0, 6.7725} -> {0, 6.58732}====>                     ] 57% 6.5s
{0, 7.76536} -> {0, 7.04494}====>                    ] 58% 6.595s
{0, 8.21379} -> {0, 7.81273}====>                    ] 59% 6.691s
{0, 5.52642} -> {0, 5.09197}=====>                   ] 60% 6.787s
{0, 5.61846} -> {0, 5.30846}=====>                   ] 61% 6.885s
{0, 6.23602} -> {0, 5.63007}=====>                   ] 61% 6.981s
{0, 9.17409} -> {0, 8.96356}======>                  ] 62% 7.076s
{0, 6.38295} -> {0, 6.27698}======>                  ] 63% 7.169s
{0, 7.70094} -> {0, 7.63325}=======>                 ] 64% 7.263s
{0, 8.90911} -> {0, 8.64375}=======>                 ] 65% 7.374s
{0, 8.90911} -> {0, 7.76502}========>                ] 66% 7.467s
{0, 5.08739} -> {0, 4.93089}========>                ] 67% 7.56s
{0, 5.61846} -> {0, 5.13288}=========>               ] 68% 7.652s
{0, 7.78294} -> {0, 7.57773}=========>               ] 69% 7.747s
{0, 5.11194} -> {0, 4.97715}=========>               ] 69% 7.84s
{0, 9.01326} -> {0, 8.78881}==========>              ] 70% 7.937s
{0, 9.41811} -> {0, 9.03182}==========>              ] 71% 8.034s
{0, 4.93296} -> {0, 4.92333}===========>             ] 72% 8.128s
{0, 6.70045} -> {0, 6.6252}============>             ] 73% 8.222s
{0, 5.81036} -> {0, 5.6146}=============>            ] 74% 8.323s
{0, 5.81036} -> {0, 5.2855}=============>            ] 75% 8.432s
{0, 5.05064} -> {0, 4.80156}=============>           ] 76% 8.526s
{0, 5.05064} -> {0, 4.80156}=============>           ] 76% 8.622s
{0, 10.5383} -> {0, 10.4045}=============>           ] 77% 8.719s
{0, 6.6802} -> {0, 6.10286}===============>          ] 78% 8.811s
{0, 5.47594} -> {0, 5.31284}==============>          ] 79% 8.906s
{0, 8.95441} -> {0, 8.70081}===============>         ] 80% 9s
{0, 8.95441} -> {0, 8.198}=================>         ] 81% 9.094s
{0, 7.94185} -> {0, 7.22833}================>        ] 82% 9.202s
{0, 5.18016} -> {0, 4.83616}================>        ] 83% 9.299s
{0, 5.58032} -> {0, 5.5231}==================>       ] 84% 9.406s
{0, 5.18716} -> {0, 4.92628}=================>       ] 84% 9.502s
{0, 7.94185} -> {0, 7.10036}=================>       ] 85% 9.595s
{0, 2.93711} -> {0, 2.7435}===================>      ] 86% 9.724s
{0, 5.52642} -> {0, 4.98943}==================>      ] 87% 9.82s
{0, 5.54847} -> {0, 5.47532}===================>     ] 88% 9.911s
{0, 9.68039} -> {0, 9.47241}===================>     ] 89% 10.004s
{0, 10.4949} -> {0, 10.167}=====================>    ] 90% 10.097s
{0, 6.69615} -> {0, 6.56536}====================>    ] 91% 10.192s
{0, 9.68039} -> {0, 8.43725}=====================>   ] 92% 10.289s
{0, 9.41811} -> {0, 9.20197}=====================>   ] 92% 10.388s
{0, 9.41811} -> {0, 9.20197}=====================>   ] 93% 10.495s
{0, 4.14825} -> {0, 4.14825}======================>  ] 94% 10.591s
{0, 0.0673623} -> {0, 0.0673623}==================>  ] 95% 10.685s
{0, 0.01} -> {0, 0.01}=============================> ] 96% 10.78s
{0, 2.28979} -> {0, 2.24283}=======================> ] 97% 10.873s
{0, 3.03497} -> {0, 2.9505}=========================>] 98% 10.967s
{-55.297, 53.387} -> {-51.2107, 50.7867}============>] 99% 11.063s
  [==================================================] 100% 64.678s
  4.5. Quantize graph...
WARN: Conv2D_2 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_9 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_20 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_26 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_33 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_44 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_50 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_56 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_62 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_35 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_68 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_74 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_11 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_80 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_86 Fallback to float conv2d due to weights divergence.
5. Lowering...
6. Optimize Pass 3...
7. Generate code...
  Plan buffers...
  Emit code...
Working memory usage: 362496 B

SUMMARY
INPUTS
0       input_1 1x3x32x32
OUTPUTS
0       Identity        1x5x32x32

.\ncc.exe compile Model_V0_1.tflite Model_V0_1.kmodel -i tflite -o kmodel --dataset ./data/JPEGImages_Sample/ --dataset-format image --inference-type uint8 --input-mean 0 --input-std 1 --dump-ir --input-type uint8 --max-allocator-solve-secs 120 --calibrate-method l2 --dump-weights-range --weights-quantize-threshold 32  --output-quantize-threshold 65535
1. Import graph...
2. Optimize Pass 1...
Dump weights range ...
Conv2D_0{-7.69981, 5.65006}
Conv2D_3{-1.20796, 1.27813}
Conv2D_4{-0.778667, 0.827375}
Conv2D_5{-2.01471, 1.77771}
Conv2D_6{-0.421971, 0.841585}
Conv2D_7{-0.719524, 0.5067}
Conv2D_12{-0.604414, 0.764012}
Conv2D_13{-0.690024, 0.857043}
Conv2D_14{-1.06358, 1.38815}
Conv2D_15{-1.23217, 1.54182}
Conv2D_16{-0.545631, 0.547883}
Conv2D_17{-2.25043, 0.942201}
Conv2D_18{-0.412925, 0.524094}
Conv2D_21{-0.659724, 0.648631}
Conv2D_22{-0.897048, 0.812928}
Conv2D_23{-0.413057, 0.535818}
Conv2D_24{-0.74034, 0.598373}
Conv2D_27{-0.587591, 0.627704}
Conv2D_28{-0.83368, 0.817675}
Conv2D_29{-0.471071, 0.345599}
Conv2D_30{-0.455182, 0.429017}
Conv2D_31{-0.450613, 0.443387}
Conv2D_36{-0.631094, 0.615425}
Conv2D_37{-0.716845, 0.864594}
Conv2D_38{-0.731777, 0.872114}
Conv2D_39{-0.864499, 1.04279}
Conv2D_40{-0.321136, 0.294978}
Conv2D_41{-0.389408, 0.618573}
Conv2D_42{-0.463768, 0.434249}
Conv2D_45{-0.628029, 0.606052}
Conv2D_46{-0.857071, 0.743852}
Conv2D_47{-0.326795, 0.319491}
Conv2D_48{-0.34, 0.583243}
Conv2D_51{-0.639259, 0.782657}
Conv2D_52{-0.792057, 0.785551}
Conv2D_53{-0.375116, 0.291687}
Conv2D_54{-0.428019, 0.417399}
Conv2D_57{-0.864689, 0.800644}
Conv2D_58{-1.12123, 0.860939}
Conv2D_59{-0.416292, 0.347888}
Conv2D_60{-0.357286, 0.383075}
Conv2D_63{-0.967548, 0.958137}
Conv2D_64{-1.25436, 1.52667}
Conv2D_65{-0.290778, 0.240788}
Conv2D_66{-0.576748, 0.549428}
Conv2D_69{-0.59016, 1.03322}
Conv2D_70{-1.12056, 0.968841}
Conv2D_71{-0.612557, 0.491848}
Conv2D_72{-1.0838, 0.808319}
Conv2D_75{-1.17118, 1.54664}
Conv2D_76{-2.04342, 7.5335}
Conv2D_77{-0.703412, 0.894966}
Conv2D_78{-1.09949, 0.698665}
Conv2D_81{-1.68518, 2.37004}
Conv2D_82{-0.987302, 1.36442}
Conv2D_83{-0.821405, 0.529464}
Conv2D_84{-1.40452, 0.955955}
Conv2D_87{9.63886, 9.63886}
Conv2D_88{-2.16083, 1.17549e-38}
Conv2D_89{-9.00428, 4.28854}
Conv2D_1{-2.07445, 2.97643}
Conv2D_2{-0.814324, 2.10761}
Conv2D_8{-1.70549, 1.33728}
Conv2D_9{-1.00268, 1.23354}
Conv2D_19{-1.24083, 1.69613}
Conv2D_20{-0.968029, 1.10703}
Conv2D_25{-1.57136, 1.99744}
Conv2D_26{-1.276, 1.15703}
Conv2D_32{-2.44768, 2.68878}
Conv2D_33{-1.91571, 2.17723}
Conv2D_43{-1.63416, 6.87644}
Conv2D_44{-2.39985, 2.38712}
Conv2D_49{-4.55612, 9.03819}
Conv2D_50{-5.61178, 20.7805}
Conv2D_55{-2.23221, 2.68983}
Conv2D_56{-1.31554, 1.76325}
Conv2D_61{-2.53103, 10.576}
Conv2D_62{-9.62121, 9.81594}
Conv2D_34{-1.33452, 1.98011}
Conv2D_35{-1.18227, 1.51693}
Conv2D_67{-12.4833, 18.4161}
Conv2D_68{-6.76074, 6.29711}
Conv2D_73{-15.2925, 25.2836}
Conv2D_74{-33.6843, 27.6947}
Conv2D_10{-1.87758, 1.64303}
Conv2D_11{-0.869822, 1.2687}
Conv2D_79{-1.52001, 2.16186}
Conv2D_80{-1.46659, 2.8314}
Conv2D_85{0.00839139, 0.0886092}
Conv2D_86{-0.0923645, 0.481875}
3. Optimize Pass 2...
4. Quantize...
  4.1. Add quantization checkpoints...
  4.2. Get activation ranges...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.805s
  4.3. Get activation distributions...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.459s
  4.4. Find optimal thresholds...
{0, 4.86935} -> {0, 4.24404}                         ] 0% 0s
{0, 9.22257} -> {0, 8.80377}                         ] 0% 0.096s
{0, 7.94185} -> {0, 6.92198}                         ] 1% 0.19s
{0, 6.67726} -> {0, 6.55663}                         ] 2% 0.301s
{0, 7.96055} -> {0, 7.52521}                         ] 3% 0.396s
{0, 6.85896} -> {0, 5.97815}                         ] 4% 0.49s
{0, 8.21379} -> {0, 7.81273}                         ] 5% 0.585s
{0, 6.24038} -> {0, 6.02099}                         ] 6% 0.681s
{0, 7.94185} -> {0, 7.22833}                         ] 7% 0.777s
{0, 12.5055} -> {0, 11.4674}                         ] 7% 0.874s
{0, 6.80435} -> {0, 6.3525}                          ] 8% 0.97s
{0, 5.99011} -> {0, 5.84972}                         ] 9% 1.063s
{0, 6.85896} -> {0, 6.20589}                         ] 10% 1.157s
{0, 8.101} -> {0, 7.06069}                           ] 11% 1.274s
{0, 8.48414} -> {0, 7.92488}                         ] 12% 1.371s
{0, 7.76536} -> {0, 7.04494}                         ] 13% 1.464s
{0, 3.03497} -> {0, 2.9505}                          ] 14% 1.556s
{0, 9.10347} -> {0, 8.41004}                         ] 15% 1.652s
{0, 5.14937} -> {0, 4.64901}                         ] 15% 1.793s
{0, 6.6166} -> {0, 6.25152}                          ] 16% 1.887s
{0, 7.46627} -> {0, 7.12723}                         ] 17% 1.98s
{0, 5.42753} -> {0, 5.30297}                         ] 18% 2.073s
{0, 4.87661} -> {0, 4.68611}                         ] 19% 2.169s
{0, 9.56657} -> {0, 8.93129}                         ] 20% 2.263s
{0, 7.94185} -> {0, 6.92198}                         ] 21% 2.368s
{0, 5.05064} -> {0, 4.80156}                         ] 22% 2.461s
{0, 11.6405} -> {0, 11.1119}                         ] 23% 2.558s
{0, 7.62972} -> {0, 6.64993}                         ] 23% 2.655s
{0, 5.15102} -> {0, 4.70835}                         ] 24% 2.759s
{0, 7.43552} -> {0, 6.66946}                         ] 25% 2.856s
{0, 7.69642} -> {0, 7.26425}                         ] 26% 2.951s
{0, 6.82579} -> {0, 6.63581}                         ] 27% 3.045s
{0, 5.53839} -> {0, 5.26255}                         ] 28% 3.139s
{0, 8.101} -> {0, 7.06069}                           ] 29% 3.233s
{0, 7.17185} -> {0, 7.05629}                         ] 30% 3.326s
{0, 11.5465} -> {0, 11.0221}                         ] 30% 3.434s
{0, 8.74409} -> {0, 7.62119}                         ] 31% 3.531s
{0, 5.34708} -> {0, 5.10427}                         ] 32% 3.642s
{0, 10.8683} -> {0, 9.4726}                          ] 33% 3.737s
{0, 8.03881} -> {0, 7.77583}                         ] 34% 3.831s
{0, 8.43533} -> {0, 7.35209}                         ] 35% 3.926s
{0, 6.5187} -> {0, 5.98078}                          ] 36% 4.025s
{0, 8.21379} -> {0, 7.15899}                         ] 37% 4.122s
{0, 6.31197} -> {0, 5.5014}                          ] 38% 4.218s
{0, 7.77231} -> {0, 7.57117}                         ] 38% 4.317s
{0, 8.74409} -> {0, 6.89536}                         ] 39% 4.423s
{0, 6.23602} -> {0, 5.4352}                          ] 40% 4.518s
{0, 6.70045} -> {0, 6.6252}                          ] 41% 4.62s
{0, 6.23602} -> {0, 5.63007}                         ] 42% 4.714s
{0, 9.40854} -> {0, 9.02724}                         ] 43% 4.81s
{0, 7.58859} -> {0, 7.27734}                         ] 44% 4.944s
{0, 6.7725} -> {0, 6.58732}                          ] 45% 5.093s
{0, 5.47594} -> {0, 5.31284}                         ] 46% 5.188s
{0, 4.8006} -> {0, 4.69746}                          ] 46% 5.281s
{0, 7.98408} -> {0, 7.73848}                         ] 47% 5.375s
{0, 7.14744} -> {0, 6.89617}                         ] 48% 5.478s
{0, 6.02894} -> {0, 5.81699}                         ] 49% 5.573s
{0, 6.23602} -> {0, 5.63007}>                        ] 50% 5.671s
{0, 7.62872} -> {0, 6.64906}>                        ] 51% 5.764s
{0, 11.2678} -> {0, 11.1578}=>                       ] 52% 5.857s
{0, 6.49012} -> {0, 6.23026}=>                       ] 53% 5.952s
{0, 8.03881} -> {0, 7.00649}=>                       ] 53% 6.047s
{0, 8.21897} -> {0, 7.79357}==>                      ] 54% 6.144s
{0, 8.43533} -> {0, 7.71042}==>                      ] 55% 6.24s
{0, 9.15786} -> {0, 8.742}=====>                     ] 56% 6.335s
{0, 6.67027} -> {0, 6.39017}===>                     ] 57% 6.431s
{0, 6.42045} -> {0, 6.12889}====>                    ] 58% 6.54s
{0, 10.7851} -> {0, 10.4744}====>                    ] 59% 6.635s
{0, 5.81036} -> {0, 5.2855}======>                   ] 60% 6.733s
{0, 6.45081} -> {0, 6.45081}=====>                   ] 61% 6.829s
{0, 5.08739} -> {0, 4.93089}=====>                   ] 61% 6.926s
{0, 7.76536} -> {0, 7.58715}======>                  ] 62% 7.02s
{0, 5.61846} -> {0, 5.30846}======>                  ] 63% 7.116s
{0, 6.23602} -> {0, 5.63007}=======>                 ] 64% 7.21s
{0, 9.17409} -> {0, 8.96356}=======>                 ] 65% 7.304s
{0, 6.38295} -> {0, 6.27698}========>                ] 66% 7.398s
{0, 7.70094} -> {0, 7.63325}========>                ] 67% 7.493s
{0, 8.90911} -> {0, 8.64375}=========>               ] 68% 7.605s
{0, 8.90911} -> {0, 7.76502}=========>               ] 69% 7.703s
{0, 5.61846} -> {0, 5.13288}=========>               ] 69% 7.797s
{0, 7.78294} -> {0, 7.57773}==========>              ] 70% 7.895s
{0, 9.01326} -> {0, 8.78881}==========>              ] 71% 7.991s
{0, 4.93296} -> {0, 4.92333}===========>             ] 72% 8.088s
{0, 5.81036} -> {0, 5.6146}============>             ] 73% 8.182s
{0, 5.05064} -> {0, 4.80156}============>            ] 74% 8.309s
{0, 10.5383} -> {0, 10.4045}============>            ] 75% 8.408s
{0, 6.6802} -> {0, 6.10286}==============>           ] 76% 8.501s
{0, 7.19098} -> {0, 6.93817}=============>           ] 76% 8.612s
{0, 8.95441} -> {0, 8.70081}=============>           ] 77% 8.708s
{0, 8.95441} -> {0, 8.198}================>          ] 78% 8.802s
{0, 5.52642} -> {0, 5.09197}==============>          ] 79% 8.9s
{0, 7.94185} -> {0, 7.22833}===============>         ] 80% 8.995s
{0, 5.18016} -> {0, 4.83616}===============>         ] 81% 9.089s
{0, 5.58032} -> {0, 5.5231}=================>        ] 82% 9.182s
{0, 7.42506} -> {0, 7.21116}================>        ] 83% 9.277s
{0, 5.11194} -> {0, 4.97715}=================>       ] 84% 9.368s
{0, 5.18716} -> {0, 4.92628}=================>       ] 84% 9.461s
{0, 7.94185} -> {0, 7.10036}=================>       ] 85% 9.563s
{0, 2.93711} -> {0, 2.7435}===================>      ] 86% 9.674s
{0, 5.52642} -> {0, 4.98943}==================>      ] 87% 9.767s
{0, 5.54847} -> {0, 5.47532}===================>     ] 88% 9.861s
{0, 9.68039} -> {0, 9.47241}===================>     ] 89% 9.955s
{0, 10.4949} -> {0, 10.167}=====================>    ] 90% 10.048s
{0, 6.69615} -> {0, 6.56536}====================>    ] 91% 10.141s
{0, 9.68039} -> {0, 8.43725}=====================>   ] 92% 10.234s
{0, 9.41811} -> {0, 9.20197}=====================>   ] 92% 10.333s
{0, 9.41811} -> {0, 9.20197}=====================>   ] 93% 10.43s
{0, 4.14825} -> {0, 4.14825}======================>  ] 94% 10.525s
{0, 0.0673623} -> {0, 0.0673623}==================>  ] 95% 10.624s
{0, 0.01} -> {0, 0.01}=============================> ] 96% 10.735s
{0, 2.28979} -> {0, 2.24283}=======================> ] 97% 10.831s
{0, 9.41811} -> {0, 9.03182}========================>] 98% 10.925s
{-55.297, 53.387} -> {-51.2107, 50.7867}============>] 99% 11.02s
  [==================================================] 100% 64.51s
  4.5. Quantize graph...
WARN: Conv2D_2 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_9 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_20 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_26 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_33 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_44 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_50 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_56 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_62 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_35 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_68 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_73 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_74 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_11 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_80 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_86 Fallback to float conv2d due to weights divergence.
5. Lowering...
6. Optimize Pass 3...
7. Generate code...
  Plan buffers...
  Emit code...
Working memory usage: 353280 B

SUMMARY
INPUTS
0       input_1 1x3x32x32
OUTPUTS
0       Identity        1x5x32x32

.\ncc.exe compile Model_V0_1.tflite Model_V0_1.kmodel -i tflite -o kmodel --dataset ./data/JPEGImages_Sample/ --dataset-format image --inference-type uint8 --input-mean 0 --input-std 1 --dump-ir --input-type uint8 --max-allocator-solve-secs 120 --calibrate-method l2 --dump-weights-range --weights-quantize-threshold 65535  --output-quantize-threshold 65535
1. Import graph...
2. Optimize Pass 1...
Dump weights range ...
Conv2D_0{-7.69981, 5.65006}
Conv2D_3{-1.20796, 1.27813}
Conv2D_4{-0.778667, 0.827375}
Conv2D_5{-2.01471, 1.77771}
Conv2D_6{-0.421971, 0.841585}
Conv2D_7{-0.719524, 0.5067}
Conv2D_12{-0.604414, 0.764012}
Conv2D_13{-0.690024, 0.857043}
Conv2D_14{-1.06358, 1.38815}
Conv2D_15{-1.23217, 1.54182}
Conv2D_16{-0.545631, 0.547883}
Conv2D_17{-2.25043, 0.942201}
Conv2D_18{-0.412925, 0.524094}
Conv2D_21{-0.659724, 0.648631}
Conv2D_22{-0.897048, 0.812928}
Conv2D_23{-0.413057, 0.535818}
Conv2D_24{-0.74034, 0.598373}
Conv2D_27{-0.587591, 0.627704}
Conv2D_28{-0.83368, 0.817675}
Conv2D_29{-0.471071, 0.345599}
Conv2D_30{-0.455182, 0.429017}
Conv2D_31{-0.450613, 0.443387}
Conv2D_36{-0.631094, 0.615425}
Conv2D_37{-0.716845, 0.864594}
Conv2D_38{-0.731777, 0.872114}
Conv2D_39{-0.864499, 1.04279}
Conv2D_40{-0.321136, 0.294978}
Conv2D_41{-0.389408, 0.618573}
Conv2D_42{-0.463768, 0.434249}
Conv2D_45{-0.628029, 0.606052}
Conv2D_46{-0.857071, 0.743852}
Conv2D_47{-0.326795, 0.319491}
Conv2D_48{-0.34, 0.583243}
Conv2D_51{-0.639259, 0.782657}
Conv2D_52{-0.792057, 0.785551}
Conv2D_53{-0.375116, 0.291687}
Conv2D_54{-0.428019, 0.417399}
Conv2D_57{-0.864689, 0.800644}
Conv2D_58{-1.12123, 0.860939}
Conv2D_59{-0.416292, 0.347888}
Conv2D_60{-0.357286, 0.383075}
Conv2D_63{-0.967548, 0.958137}
Conv2D_64{-1.25436, 1.52667}
Conv2D_65{-0.290778, 0.240788}
Conv2D_66{-0.576748, 0.549428}
Conv2D_69{-0.59016, 1.03322}
Conv2D_70{-1.12056, 0.968841}
Conv2D_71{-0.612557, 0.491848}
Conv2D_72{-1.0838, 0.808319}
Conv2D_75{-1.17118, 1.54664}
Conv2D_76{-2.04342, 7.5335}
Conv2D_77{-0.703412, 0.894966}
Conv2D_78{-1.09949, 0.698665}
Conv2D_81{-1.68518, 2.37004}
Conv2D_82{-0.987302, 1.36442}
Conv2D_83{-0.821405, 0.529464}
Conv2D_84{-1.40452, 0.955955}
Conv2D_87{9.63886, 9.63886}
Conv2D_88{-2.16083, 1.17549e-38}
Conv2D_89{-9.00428, 4.28854}
Conv2D_1{-2.07445, 2.97643}
Conv2D_2{-0.814324, 2.10761}
Conv2D_8{-1.70549, 1.33728}
Conv2D_9{-1.00268, 1.23354}
Conv2D_19{-1.24083, 1.69613}
Conv2D_20{-0.968029, 1.10703}
Conv2D_25{-1.57136, 1.99744}
Conv2D_26{-1.276, 1.15703}
Conv2D_32{-2.44768, 2.68878}
Conv2D_33{-1.91571, 2.17723}
Conv2D_43{-1.63416, 6.87644}
Conv2D_44{-2.39985, 2.38712}
Conv2D_49{-4.55612, 9.03819}
Conv2D_50{-5.61178, 20.7805}
Conv2D_55{-2.23221, 2.68983}
Conv2D_56{-1.31554, 1.76325}
Conv2D_61{-2.53103, 10.576}
Conv2D_62{-9.62121, 9.81594}
Conv2D_34{-1.33452, 1.98011}
Conv2D_35{-1.18227, 1.51693}
Conv2D_67{-12.4833, 18.4161}
Conv2D_68{-6.76074, 6.29711}
Conv2D_73{-15.2925, 25.2836}
Conv2D_74{-33.6843, 27.6947}
Conv2D_10{-1.87758, 1.64303}
Conv2D_11{-0.869822, 1.2687}
Conv2D_79{-1.52001, 2.16186}
Conv2D_80{-1.46659, 2.8314}
Conv2D_85{0.00839139, 0.0886092}
Conv2D_86{-0.0923645, 0.481875}
3. Optimize Pass 2...
4. Quantize...
  4.1. Add quantization checkpoints...
  4.2. Get activation ranges...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.802s
  4.3. Get activation distributions...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.482s
  4.4. Find optimal thresholds...
{0, 7.17185} -> {0, 7.05629}                         ] 0% 0s
{0, 7.46627} -> {0, 7.12723}                         ] 0% 0.106s
{0, 8.101} -> {0, 7.06069}                           ] 1% 0.207s
{0, 4.86935} -> {0, 4.24404}                         ] 2% 0.306s
{0, 6.80435} -> {0, 6.3525}                          ] 3% 0.404s
{0, 6.42045} -> {0, 6.12889}                         ] 4% 0.501s
{0, 7.14744} -> {0, 6.89617}                         ] 5% 0.597s
{0, 7.94185} -> {0, 6.92198}                         ] 6% 0.695s
{0, 7.96055} -> {0, 7.52521}                         ] 7% 0.788s
{0, 6.85896} -> {0, 5.97815}                         ] 7% 0.89s
{0, 5.14937} -> {0, 4.64901}                         ] 8% 0.986s
{0, 10.7851} -> {0, 10.4744}                         ] 9% 1.08s
{0, 12.5055} -> {0, 11.4674}                         ] 10% 1.188s
{0, 6.23602} -> {0, 5.63007}                         ] 11% 1.322s
{0, 6.85896} -> {0, 6.20589}                         ] 12% 1.417s
{0, 10.8683} -> {0, 9.4726}                          ] 13% 1.508s
{0, 7.94185} -> {0, 7.22833}                         ] 14% 1.602s
{0, 8.48414} -> {0, 7.92488}                         ] 15% 1.698s
{0, 6.24038} -> {0, 6.02099}                         ] 15% 1.791s
{0, 8.21379} -> {0, 7.15899}                         ] 16% 1.891s
{0, 9.10347} -> {0, 8.41004}                         ] 17% 1.986s
{0, 5.99011} -> {0, 5.84972}                         ] 18% 2.086s
{0, 6.6166} -> {0, 6.25152}                          ] 19% 2.19s
{0, 4.87661} -> {0, 4.68611}                         ] 20% 2.286s
{0, 7.94185} -> {0, 6.92198}                         ] 21% 2.382s
{0, 9.40854} -> {0, 9.02724}                         ] 22% 2.475s
{0, 7.62972} -> {0, 6.64993}                         ] 23% 2.567s
{0, 7.77231} -> {0, 7.57117}                         ] 23% 2.661s
{0, 4.93296} -> {0, 4.92333}                         ] 24% 2.764s
{0, 8.43533} -> {0, 7.35209}                         ] 25% 2.858s
{0, 7.69642} -> {0, 7.26425}                         ] 26% 2.954s
{0, 11.5465} -> {0, 11.0221}                         ] 27% 3.05s
{0, 5.15102} -> {0, 4.70835}                         ] 28% 3.145s
{0, 6.82579} -> {0, 6.63581}                         ] 29% 3.25s
{0, 5.53839} -> {0, 5.26255}                         ] 30% 3.344s
{0, 6.67726} -> {0, 6.55663}                         ] 30% 3.443s
{0, 8.101} -> {0, 7.06069}                           ] 31% 3.545s
{0, 7.76536} -> {0, 7.58715}                         ] 32% 3.64s
{0, 8.74409} -> {0, 7.62119}                         ] 33% 3.74s
{0, 6.45081} -> {0, 6.45081}                         ] 34% 3.837s
{0, 9.56657} -> {0, 8.93129}                         ] 35% 3.932s
{0, 6.02894} -> {0, 5.81699}                         ] 36% 4.027s
{0, 6.5187} -> {0, 5.98078}                          ] 37% 4.126s
{0, 8.74409} -> {0, 6.89536}                         ] 38% 4.222s
{0, 7.43552} -> {0, 6.66946}                         ] 38% 4.338s
{0, 6.31197} -> {0, 5.5014}                          ] 39% 4.435s
{0, 6.23602} -> {0, 5.4352}                          ] 40% 4.563s
{0, 7.58859} -> {0, 7.27734}                         ] 41% 4.658s
{0, 3.03497} -> {0, 2.9505}                          ] 42% 4.753s
{0, 6.23602} -> {0, 5.63007}                         ] 43% 4.852s
{0, 4.8006} -> {0, 4.69746}                          ] 44% 4.947s
{0, 11.2678} -> {0, 11.1578}                         ] 45% 5.043s
{0, 6.49012} -> {0, 6.23026}                         ] 46% 5.138s
{0, 8.21897} -> {0, 7.79357}                         ] 46% 5.236s
{0, 8.03881} -> {0, 7.77583}                         ] 47% 5.345s
{0, 8.03881} -> {0, 7.00649}                         ] 48% 5.44s
{0, 11.6405} -> {0, 11.1119}                         ] 49% 5.535s
{0, 4.14825} -> {0, 4.14825}>                        ] 50% 5.628s
{0, 8.43533} -> {0, 7.71042}>                        ] 51% 5.724s
{0, 9.15786} -> {0, 8.742}===>                       ] 52% 5.824s
{0, 6.67027} -> {0, 6.39017}=>                       ] 53% 5.919s
{0, 7.62872} -> {0, 6.64906}=>                       ] 53% 6.012s
{0, 5.05064} -> {0, 4.80156}==>                      ] 54% 6.109s
{0, 9.22257} -> {0, 8.80377}==>                      ] 55% 6.203s
{0, 6.7725} -> {0, 6.58732}====>                     ] 56% 6.299s
{0, 8.21379} -> {0, 7.81273}===>                     ] 57% 6.41s
{0, 5.34708} -> {0, 5.10427}====>                    ] 58% 6.504s
{0, 7.76536} -> {0, 7.04494}====>                    ] 59% 6.599s
{0, 5.61846} -> {0, 5.30846}=====>                   ] 60% 6.693s
{0, 6.23602} -> {0, 5.63007}=====>                   ] 61% 6.79s
{0, 7.98408} -> {0, 7.73848}=====>                   ] 61% 6.885s
{0, 9.17409} -> {0, 8.96356}======>                  ] 62% 6.983s
{0, 6.38295} -> {0, 6.27698}======>                  ] 63% 7.08s
{0, 7.70094} -> {0, 7.63325}=======>                 ] 64% 7.176s
{0, 8.90911} -> {0, 8.64375}=======>                 ] 65% 7.274s
{0, 0.01} -> {0, 0.01}==============>                ] 66% 7.372s
{0, 8.90911} -> {0, 7.76502}========>                ] 67% 7.485s
{0, 5.08739} -> {0, 4.93089}=========>               ] 68% 7.579s
{0, 5.61846} -> {0, 5.13288}=========>               ] 69% 7.674s
{0, 7.78294} -> {0, 7.57773}=========>               ] 69% 7.772s
{0, 9.01326} -> {0, 8.78881}==========>              ] 70% 7.87s
{0, 6.70045} -> {0, 6.6252}===========>              ] 71% 7.971s
{0, 5.81036} -> {0, 5.6146}============>             ] 72% 8.067s
{0, 5.81036} -> {0, 5.2855}============>             ] 73% 8.198s
{0, 5.05064} -> {0, 4.80156}============>            ] 74% 8.292s
{0, 10.5383} -> {0, 10.4045}============>            ] 75% 8.385s
{0, 6.6802} -> {0, 6.10286}==============>           ] 76% 8.493s
{0, 7.19098} -> {0, 6.93817}=============>           ] 76% 8.585s
{0, 5.47594} -> {0, 5.31284}=============>           ] 77% 8.678s
{0, 8.95441} -> {0, 8.70081}==============>          ] 78% 8.785s
{0, 8.95441} -> {0, 8.198}================>          ] 79% 8.878s
{0, 5.52642} -> {0, 5.09197}===============>         ] 80% 8.973s
{-55.297, 53.387} -> {-51.2107, 50.7867}===>         ] 81% 9.067s
{0, 7.94185} -> {0, 7.22833}================>        ] 82% 62.688s
{0, 5.18016} -> {0, 4.83616}================>        ] 83% 62.784s
{0, 5.58032} -> {0, 5.5231}==================>       ] 84% 62.88s
{0, 7.42506} -> {0, 7.21116}=================>       ] 84% 62.974s
{0, 5.11194} -> {0, 4.97715}=================>       ] 85% 63.067s
{0, 5.18716} -> {0, 4.92628}==================>      ] 86% 63.166s
{0, 7.94185} -> {0, 7.10036}==================>      ] 87% 63.259s
{0, 2.93711} -> {0, 2.7435}====================>     ] 88% 63.352s
{0, 5.52642} -> {0, 4.98943}===================>     ] 89% 63.452s
{0, 5.42753} -> {0, 5.30297}====================>    ] 90% 63.545s
{0, 5.54847} -> {0, 5.47532}====================>    ] 91% 63.641s
{0, 9.68039} -> {0, 9.47241}=====================>   ] 92% 63.759s
{0, 10.4949} -> {0, 10.167}======================>   ] 92% 63.854s
{0, 6.69615} -> {0, 6.56536}=====================>   ] 93% 63.947s
{0, 9.68039} -> {0, 8.43725}======================>  ] 94% 64.041s
{0, 9.41811} -> {0, 9.20197}======================>  ] 95% 64.136s
{0, 9.41811} -> {0, 9.20197}=======================> ] 96% 64.235s
{0, 0.0673623} -> {0, 0.0673623}===================> ] 97% 64.33s
{0, 2.28979} -> {0, 2.24283}========================>] 98% 64.426s
{0, 9.41811} -> {0, 9.03182}========================>] 99% 64.524s
  [==================================================] 100% 64.618s
  4.5. Quantize graph...
WARN: Conv2D_2 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_9 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_20 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_26 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_33 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_44 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_50 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_56 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_62 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_35 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_68 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_74 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_11 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_80 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_86 Fallback to float conv2d due to weights divergence.
5. Lowering...
6. Optimize Pass 3...
7. Generate code...
  Plan buffers...
  Emit code...
Working memory usage: 362496 B

SUMMARY
INPUTS
0       input_1 1x3x32x32
OUTPUTS
0       Identity        1x5x32x32

.\ncc.exe compile Model_V0_1.tflite Model_V0_1.kmodel -i tflite -o kmodel --dataset ./data/JPEGImages_Sample/ --dataset-format image --inference-type uint8 --input-mean 0 --input-std 1 --dump-ir --input-type uint8 --max-allocator-solve-secs 120 --calibrate-method l2 --dump-weights-range --weights-quantize-threshold 8  --output-quantize-threshold 1024
1. Import graph...
2. Optimize Pass 1...
Dump weights range ...
Conv2D_0{-7.69981, 5.65006}
Conv2D_3{-1.20796, 1.27813}
Conv2D_4{-0.778667, 0.827375}
Conv2D_5{-2.01471, 1.77771}
Conv2D_6{-0.421971, 0.841585}
Conv2D_7{-0.719524, 0.5067}
Conv2D_12{-0.604414, 0.764012}
Conv2D_13{-0.690024, 0.857043}
Conv2D_14{-1.06358, 1.38815}
Conv2D_15{-1.23217, 1.54182}
Conv2D_16{-0.545631, 0.547883}
Conv2D_17{-2.25043, 0.942201}
Conv2D_18{-0.412925, 0.524094}
Conv2D_21{-0.659724, 0.648631}
Conv2D_22{-0.897048, 0.812928}
Conv2D_23{-0.413057, 0.535818}
Conv2D_24{-0.74034, 0.598373}
Conv2D_27{-0.587591, 0.627704}
Conv2D_28{-0.83368, 0.817675}
Conv2D_29{-0.471071, 0.345599}
Conv2D_30{-0.455182, 0.429017}
Conv2D_31{-0.450613, 0.443387}
Conv2D_36{-0.631094, 0.615425}
Conv2D_37{-0.716845, 0.864594}
Conv2D_38{-0.731777, 0.872114}
Conv2D_39{-0.864499, 1.04279}
Conv2D_40{-0.321136, 0.294978}
Conv2D_41{-0.389408, 0.618573}
Conv2D_42{-0.463768, 0.434249}
Conv2D_45{-0.628029, 0.606052}
Conv2D_46{-0.857071, 0.743852}
Conv2D_47{-0.326795, 0.319491}
Conv2D_48{-0.34, 0.583243}
Conv2D_51{-0.639259, 0.782657}
Conv2D_52{-0.792057, 0.785551}
Conv2D_53{-0.375116, 0.291687}
Conv2D_54{-0.428019, 0.417399}
Conv2D_57{-0.864689, 0.800644}
Conv2D_58{-1.12123, 0.860939}
Conv2D_59{-0.416292, 0.347888}
Conv2D_60{-0.357286, 0.383075}
Conv2D_63{-0.967548, 0.958137}
Conv2D_64{-1.25436, 1.52667}
Conv2D_65{-0.290778, 0.240788}
Conv2D_66{-0.576748, 0.549428}
Conv2D_69{-0.59016, 1.03322}
Conv2D_70{-1.12056, 0.968841}
Conv2D_71{-0.612557, 0.491848}
Conv2D_72{-1.0838, 0.808319}
Conv2D_75{-1.17118, 1.54664}
Conv2D_76{-2.04342, 7.5335}
Conv2D_77{-0.703412, 0.894966}
Conv2D_78{-1.09949, 0.698665}
Conv2D_81{-1.68518, 2.37004}
Conv2D_82{-0.987302, 1.36442}
Conv2D_83{-0.821405, 0.529464}
Conv2D_84{-1.40452, 0.955955}
Conv2D_87{9.63886, 9.63886}
Conv2D_88{-2.16083, 1.17549e-38}
Conv2D_89{-9.00428, 4.28854}
Conv2D_1{-2.07445, 2.97643}
Conv2D_2{-0.814324, 2.10761}
Conv2D_8{-1.70549, 1.33728}
Conv2D_9{-1.00268, 1.23354}
Conv2D_19{-1.24083, 1.69613}
Conv2D_20{-0.968029, 1.10703}
Conv2D_25{-1.57136, 1.99744}
Conv2D_26{-1.276, 1.15703}
Conv2D_32{-2.44768, 2.68878}
Conv2D_33{-1.91571, 2.17723}
Conv2D_43{-1.63416, 6.87644}
Conv2D_44{-2.39985, 2.38712}
Conv2D_49{-4.55612, 9.03819}
Conv2D_50{-5.61178, 20.7805}
Conv2D_55{-2.23221, 2.68983}
Conv2D_56{-1.31554, 1.76325}
Conv2D_61{-2.53103, 10.576}
Conv2D_62{-9.62121, 9.81594}
Conv2D_34{-1.33452, 1.98011}
Conv2D_35{-1.18227, 1.51693}
Conv2D_67{-12.4833, 18.4161}
Conv2D_68{-6.76074, 6.29711}
Conv2D_73{-15.2925, 25.2836}
Conv2D_74{-33.6843, 27.6947}
Conv2D_10{-1.87758, 1.64303}
Conv2D_11{-0.869822, 1.2687}
Conv2D_79{-1.52001, 2.16186}
Conv2D_80{-1.46659, 2.8314}
Conv2D_85{0.00839139, 0.0886092}
Conv2D_86{-0.0923645, 0.481875}
3. Optimize Pass 2...
4. Quantize...
  4.1. Add quantization checkpoints...
  4.2. Get activation ranges...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.834s
  4.3. Get activation distributions...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.548s
  4.4. Find optimal thresholds...
{0, 6.42045} -> {0, 6.12889}                         ] 0% 0s
{0, 6.67726} -> {0, 6.55663}                         ] 0% 0.091s
{0, 4.86935} -> {0, 4.24404}                         ] 1% 0.184s
{0, 6.85896} -> {0, 5.97815}                         ] 2% 0.277s
{0, 7.94185} -> {0, 7.22833}                         ] 3% 0.381s
{0, 7.96055} -> {0, 7.52521}                         ] 4% 0.474s
{0, 6.85896} -> {0, 6.20589}                         ] 5% 0.568s
{0, 7.17185} -> {0, 7.05629}                         ] 6% 0.663s
{0, 9.40854} -> {0, 9.02724}                         ] 7% 0.759s
{0, 6.80435} -> {0, 6.3525}                          ] 8% 0.852s
{0, 8.43533} -> {0, 7.71042}                         ] 9% 0.947s
{0, 12.5055} -> {0, 11.4674}                         ] 10% 1.056s
{0, 7.69642} -> {0, 7.26425}                         ] 11% 1.149s
{0, 7.94185} -> {0, 6.92198}                         ] 12% 1.243s
{0, 9.22257} -> {0, 8.80377}                         ] 12% 1.347s
{0, 8.48414} -> {0, 7.92488}                         ] 13% 1.441s
{0, 6.6166} -> {0, 6.25152}                          ] 14% 1.537s
{0, 9.10347} -> {0, 8.41004}                         ] 15% 1.635s
{0, 5.14937} -> {0, 4.64901}                         ] 16% 1.73s
{0, 4.87661} -> {0, 4.68611}                         ] 17% 1.829s
{0, 7.94185} -> {0, 6.92198}                         ] 18% 1.925s
{0, 5.53839} -> {0, 5.26255}                         ] 19% 2.019s
{0, 8.101} -> {0, 7.06069}                           ] 20% 2.133s
{0, 7.62972} -> {0, 6.64993}                         ] 21% 2.256s
{0, 5.15102} -> {0, 4.70835}                         ] 22% 2.35s
{0, 6.82579} -> {0, 6.63581}                         ] 23% 2.449s
{0, 8.101} -> {0, 7.06069}                           ] 24% 2.546s
{0, 8.74409} -> {0, 7.62119}                         ] 25% 2.641s
{0, 9.56657} -> {0, 8.93129}                         ] 25% 2.735s
{0, 10.8683} -> {0, 9.4726}                          ] 26% 2.833s
{0, 6.5187} -> {0, 5.98078}                          ] 27% 2.928s
{0, 7.43552} -> {0, 6.66946}                         ] 28% 3.023s
{0, 6.31197} -> {0, 5.5014}                          ] 29% 3.135s
{0, 7.46627} -> {0, 7.12723}                         ] 30% 3.23s
{0, 8.74409} -> {0, 6.89536}                         ] 31% 3.323s
{0, 6.23602} -> {0, 5.4352}                          ] 32% 3.418s
{0, 5.34708} -> {0, 5.10427}                         ] 33% 3.512s
{0, 5.54847} -> {0, 5.47532}                         ] 34% 3.605s
{0, 6.23602} -> {0, 5.63007}                         ] 35% 3.701s
{0, 8.03881} -> {0, 7.77583}                         ] 36% 3.797s
{0, 2.93711} -> {0, 2.7435}                          ] 37% 3.896s
{0, 7.58859} -> {0, 7.27734}                         ] 37% 3.99s
{0, 6.7725} -> {0, 6.58732}                          ] 38% 4.084s
{0, 4.8006} -> {0, 4.69746}                          ] 39% 4.194s
{0, 7.14744} -> {0, 6.89617}                         ] 40% 4.288s
{0, 6.02894} -> {0, 5.81699}                         ] 41% 4.384s
{0, 6.49012} -> {0, 6.23026}                         ] 42% 4.477s
{0, 6.23602} -> {0, 5.63007}                         ] 43% 4.57s
{0, 6.24038} -> {0, 6.02099}                         ] 44% 4.665s
{0, 9.15786} -> {0, 8.742}                           ] 45% 4.757s
{0, 7.77231} -> {0, 7.57117}                         ] 46% 4.851s
{0, 11.2678} -> {0, 11.1578}                         ] 47% 4.943s
{0, 8.21897} -> {0, 7.79357}                         ] 48% 5.037s
{0, 8.03881} -> {0, 7.00649}                         ] 49% 5.132s
{0, 5.99011} -> {0, 5.84972}>                        ] 50% 5.242s
{0, 11.5465} -> {0, 11.0221}>                        ] 50% 5.4s
{0, 11.6405} -> {0, 11.1119}>                        ] 51% 5.493s
{0, 6.67027} -> {0, 6.39017}=>                       ] 52% 5.587s
{0, 8.43533} -> {0, 7.35209}=>                       ] 53% 5.685s
{0, 7.62872} -> {0, 6.64906}==>                      ] 54% 5.78s
{0, 8.21379} -> {0, 7.81273}==>                      ] 55% 5.872s
{0, 8.21379} -> {0, 7.15899}===>                     ] 56% 5.965s
{0, 10.7851} -> {0, 10.4744}===>                     ] 57% 6.059s
{0, 6.45081} -> {0, 6.45081}====>                    ] 58% 6.151s
{0, 7.76536} -> {0, 7.58715}====>                    ] 59% 6.268s
{0, 7.76536} -> {0, 7.04494}=====>                   ] 60% 6.36s
{0, 8.90911} -> {0, 8.64375}=====>                   ] 61% 6.453s
{0, 5.61846} -> {0, 5.30846}======>                  ] 62% 6.548s
{0, 6.23602} -> {0, 5.63007}======>                  ] 62% 6.642s
{0, 7.98408} -> {0, 7.73848}======>                  ] 63% 6.738s
{0, 9.17409} -> {0, 8.96356}=======>                 ] 64% 6.835s
{0, 6.38295} -> {0, 6.27698}=======>                 ] 65% 6.93s
{0, 7.70094} -> {0, 7.63325}========>                ] 66% 7.023s
{0, 8.90911} -> {0, 7.76502}========>                ] 67% 7.118s
{0, 5.08739} -> {0, 4.93089}=========>               ] 68% 7.212s
{0, 5.61846} -> {0, 5.13288}=========>               ] 69% 7.32s
{0, 7.78294} -> {0, 7.57773}==========>              ] 70% 7.414s
{0, 9.01326} -> {0, 8.78881}==========>              ] 71% 7.509s
{0, 4.93296} -> {0, 4.92333}===========>             ] 72% 7.609s
{0, 6.70045} -> {0, 6.6252}============>             ] 73% 7.709s
{0, 5.81036} -> {0, 5.6146}=============>            ] 74% 7.805s
{0, 5.81036} -> {0, 5.2855}=============>            ] 75% 7.901s
{0, 5.05064} -> {0, 4.80156}============>            ] 75% 7.996s
{0, 5.05064} -> {0, 4.80156}=============>           ] 76% 8.093s
{0, 10.5383} -> {0, 10.4045}=============>           ] 77% 8.187s
{0, 6.6802} -> {0, 6.10286}===============>          ] 78% 8.283s
{0, 7.19098} -> {0, 6.93817}==============>          ] 79% 8.409s
{0, 8.95441} -> {0, 8.198}=================>         ] 80% 8.505s
{0, 5.52642} -> {0, 5.09197}===============>         ] 81% 8.597s
{0, 7.94185} -> {0, 7.22833}================>        ] 82% 8.692s
{0, 5.18016} -> {0, 4.83616}================>        ] 83% 8.79s
{0, 5.58032} -> {0, 5.5231}==================>       ] 84% 8.885s
{0, 7.42506} -> {0, 7.21116}=================>       ] 85% 8.976s
{0, 5.11194} -> {0, 4.97715}==================>      ] 86% 9.07s
{0, 5.18716} -> {0, 4.92628}==================>      ] 87% 9.164s
{0, 7.94185} -> {0, 7.10036}==================>      ] 87% 9.261s
{0, 5.52642} -> {0, 4.98943}===================>     ] 88% 9.37s
{0, 5.42753} -> {0, 5.30297}===================>     ] 89% 9.469s
{0, 9.68039} -> {0, 9.47241}====================>    ] 90% 9.564s
{0, 10.4949} -> {0, 10.167}=====================>    ] 91% 9.658s
{0, 6.69615} -> {0, 6.56536}=====================>   ] 92% 9.753s
{0, 9.68039} -> {0, 8.43725}=====================>   ] 93% 9.849s
{0, 9.41811} -> {0, 9.20197}======================>  ] 94% 9.944s
{0, 9.41811} -> {0, 9.20197}======================>  ] 95% 10.04s
{0, 3.03497} -> {0, 2.9505}========================> ] 96% 10.136s
{0, 4.14825} -> {0, 4.14825}=======================> ] 97% 10.231s
{0, 0.0673623} -> {0, 0.0673623}====================>] 98% 10.328s
{0, 2.28979} -> {0, 2.24283}========================>] 99% 10.439s
  [==================================================] 100% 10.536s
  4.5. Quantize graph...
WARN: Conv2D_0 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_76 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_87 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_89 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_2 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_9 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_20 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_26 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_33 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_43 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_44 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_49 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_50 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_56 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_61 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_62 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_35 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_67 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_68 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_73 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_74 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_11 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_80 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_86 Fallback to float conv2d due to weights divergence.
5. Lowering...
6. Optimize Pass 3...
7. Generate code...
  Plan buffers...
  Emit code...
Working memory usage: 365568 B

SUMMARY
INPUTS
0       input_1 1x3x32x32
OUTPUTS
0       Identity        1x5x32x32

.\ncc.exe compile Model_V0_1.tflite Model_V0_1.kmodel -i tflite -o kmodel --dataset ./data/JPEGImages_Sample/ --dataset-format image --inference-type uint8 --input-mean 0 --input-std 1 --dump-ir --input-type uint8 --max-allocator-solve-secs 120 --calibrate-method l2 --dump-weights-range --weights-quantize-threshold 32 --output-quantize-threshold 8
1. Import graph...
2. Optimize Pass 1...
Dump weights range ...
Conv2D_0{-7.69981, 5.65006}
Conv2D_3{-1.20796, 1.27813}
Conv2D_4{-0.778667, 0.827375}
Conv2D_5{-2.01471, 1.77771}
Conv2D_6{-0.421971, 0.841585}
Conv2D_7{-0.719524, 0.5067}
Conv2D_12{-0.604414, 0.764012}
Conv2D_13{-0.690024, 0.857043}
Conv2D_14{-1.06358, 1.38815}
Conv2D_15{-1.23217, 1.54182}
Conv2D_16{-0.545631, 0.547883}
Conv2D_17{-2.25043, 0.942201}
Conv2D_18{-0.412925, 0.524094}
Conv2D_21{-0.659724, 0.648631}
Conv2D_22{-0.897048, 0.812928}
Conv2D_23{-0.413057, 0.535818}
Conv2D_24{-0.74034, 0.598373}
Conv2D_27{-0.587591, 0.627704}
Conv2D_28{-0.83368, 0.817675}
Conv2D_29{-0.471071, 0.345599}
Conv2D_30{-0.455182, 0.429017}
Conv2D_31{-0.450613, 0.443387}
Conv2D_36{-0.631094, 0.615425}
Conv2D_37{-0.716845, 0.864594}
Conv2D_38{-0.731777, 0.872114}
Conv2D_39{-0.864499, 1.04279}
Conv2D_40{-0.321136, 0.294978}
Conv2D_41{-0.389408, 0.618573}
Conv2D_42{-0.463768, 0.434249}
Conv2D_45{-0.628029, 0.606052}
Conv2D_46{-0.857071, 0.743852}
Conv2D_47{-0.326795, 0.319491}
Conv2D_48{-0.34, 0.583243}
Conv2D_51{-0.639259, 0.782657}
Conv2D_52{-0.792057, 0.785551}
Conv2D_53{-0.375116, 0.291687}
Conv2D_54{-0.428019, 0.417399}
Conv2D_57{-0.864689, 0.800644}
Conv2D_58{-1.12123, 0.860939}
Conv2D_59{-0.416292, 0.347888}
Conv2D_60{-0.357286, 0.383075}
Conv2D_63{-0.967548, 0.958137}
Conv2D_64{-1.25436, 1.52667}
Conv2D_65{-0.290778, 0.240788}
Conv2D_66{-0.576748, 0.549428}
Conv2D_69{-0.59016, 1.03322}
Conv2D_70{-1.12056, 0.968841}
Conv2D_71{-0.612557, 0.491848}
Conv2D_72{-1.0838, 0.808319}
Conv2D_75{-1.17118, 1.54664}
Conv2D_76{-2.04342, 7.5335}
Conv2D_77{-0.703412, 0.894966}
Conv2D_78{-1.09949, 0.698665}
Conv2D_81{-1.68518, 2.37004}
Conv2D_82{-0.987302, 1.36442}
Conv2D_83{-0.821405, 0.529464}
Conv2D_84{-1.40452, 0.955955}
Conv2D_87{9.63886, 9.63886}
Conv2D_88{-2.16083, 1.17549e-38}
Conv2D_89{-9.00428, 4.28854}
Conv2D_1{-2.07445, 2.97643}
Conv2D_2{-0.814324, 2.10761}
Conv2D_8{-1.70549, 1.33728}
Conv2D_9{-1.00268, 1.23354}
Conv2D_19{-1.24083, 1.69613}
Conv2D_20{-0.968029, 1.10703}
Conv2D_25{-1.57136, 1.99744}
Conv2D_26{-1.276, 1.15703}
Conv2D_32{-2.44768, 2.68878}
Conv2D_33{-1.91571, 2.17723}
Conv2D_43{-1.63416, 6.87644}
Conv2D_44{-2.39985, 2.38712}
Conv2D_49{-4.55612, 9.03819}
Conv2D_50{-5.61178, 20.7805}
Conv2D_55{-2.23221, 2.68983}
Conv2D_56{-1.31554, 1.76325}
Conv2D_61{-2.53103, 10.576}
Conv2D_62{-9.62121, 9.81594}
Conv2D_34{-1.33452, 1.98011}
Conv2D_35{-1.18227, 1.51693}
Conv2D_67{-12.4833, 18.4161}
Conv2D_68{-6.76074, 6.29711}
Conv2D_73{-15.2925, 25.2836}
Conv2D_74{-33.6843, 27.6947}
Conv2D_10{-1.87758, 1.64303}
Conv2D_11{-0.869822, 1.2687}
Conv2D_79{-1.52001, 2.16186}
Conv2D_80{-1.46659, 2.8314}
Conv2D_85{0.00839139, 0.0886092}
Conv2D_86{-0.0923645, 0.481875}
3. Optimize Pass 2...
4. Quantize...
  4.1. Add quantization checkpoints...
  4.2. Get activation ranges...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.986s
  4.3. Get activation distributions...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.514s
  4.4. Find optimal thresholds...
{0, 4.86935} -> {0, 4.24404}                         ] 0% 0s
{0, 7.78294} -> {0, 7.57773}                         ] 0% 0.096s
{0, 6.24038} -> {0, 6.02099}                         ] 1% 0.189s
{0, 9.01326} -> {0, 8.78881}                         ] 2% 0.281s
{0, 6.80435} -> {0, 6.3525}                          ] 3% 0.373s
{0, 7.96055} -> {0, 7.52521}                         ] 4% 0.463s
{0, 6.85896} -> {0, 5.97815}                         ] 5% 0.559s
{0, 12.5055} -> {0, 11.4674}                         ] 6% 0.65s
{0, 11.5465} -> {0, 11.0221}                         ] 7% 0.741s
{0, 7.76536} -> {0, 7.04494}                         ] 7% 0.843s
{0, 6.85896} -> {0, 6.20589}                         ] 8% 0.932s
{0, 7.17185} -> {0, 7.05629}                         ] 9% 1.024s
{0, 7.77231} -> {0, 7.57117}                         ] 10% 1.113s
{0, 6.45081} -> {0, 6.45081}                         ] 11% 1.235s
{0, 7.94185} -> {0, 7.22833}                         ] 12% 1.324s
{0, 6.6166} -> {0, 6.25152}                          ] 13% 1.414s
{0, 5.81036} -> {0, 5.6146}                          ] 14% 1.507s
{0, 8.74409} -> {0, 6.89536}                         ] 15% 1.6s
{0, 7.94185} -> {0, 6.92198}                         ] 15% 1.691s
{0, 8.43533} -> {0, 7.35209}                         ] 16% 1.782s
{0, 8.48414} -> {0, 7.92488}                         ] 17% 1.888s
{0, 8.74409} -> {0, 7.62119}                         ] 18% 1.98s
{0, 6.49012} -> {0, 6.23026}                         ] 19% 2.072s
{0, 9.10347} -> {0, 8.41004}                         ] 20% 2.166s
{0, 5.14937} -> {0, 4.64901}                         ] 21% 2.26s
{0, 10.7851} -> {0, 10.4744}                         ] 22% 2.352s
{0, 4.87661} -> {0, 4.68611}                         ] 23% 2.444s
{0, 5.61846} -> {0, 5.30846}                         ] 23% 2.534s
{0, 7.94185} -> {0, 6.92198}                         ] 24% 2.628s
{0, 4.14825} -> {0, 4.14825}                         ] 25% 2.717s
{0, 9.40854} -> {0, 9.02724}                         ] 26% 2.809s
{0, 8.101} -> {0, 7.06069}                           ] 27% 2.913s
{0, 7.62972} -> {0, 6.64993}                         ] 28% 3.006s
{0, 7.14744} -> {0, 6.89617}                         ] 29% 3.101s
{0, 7.69642} -> {0, 7.26425}                         ] 30% 3.194s
{0, 6.5187} -> {0, 5.98078}                          ] 30% 3.285s
{0, 7.62872} -> {0, 6.64906}                         ] 31% 3.382s
{0, 5.15102} -> {0, 4.70835}                         ] 32% 3.479s
{0, 9.22257} -> {0, 8.80377}                         ] 33% 3.576s
{0, 6.82579} -> {0, 6.63581}                         ] 34% 3.673s
{0, 7.58859} -> {0, 7.27734}                         ] 35% 3.768s
{0, 5.53839} -> {0, 5.26255}                         ] 36% 3.859s
{0, 8.101} -> {0, 7.06069}                           ] 37% 3.965s
{0, 9.15786} -> {0, 8.742}                           ] 38% 4.055s
{0, 9.56657} -> {0, 8.93129}                         ] 38% 4.15s
{0, 10.8683} -> {0, 9.4726}                          ] 39% 4.244s
{0, 8.21379} -> {0, 7.15899}                         ] 40% 4.337s
{0, 7.43552} -> {0, 6.66946}                         ] 41% 4.441s
{0, 11.6405} -> {0, 11.1119}                         ] 42% 4.534s
{0, 6.31197} -> {0, 5.5014}                          ] 43% 4.682s
{0, 9.41811} -> {0, 9.03182}                         ] 44% 4.772s
{0, 6.23602} -> {0, 5.4352}                          ] 45% 4.862s
{0, 6.23602} -> {0, 5.63007}                         ] 46% 4.956s
{0, 8.43533} -> {0, 7.71042}                         ] 46% 5.058s
{0, 6.67726} -> {0, 6.55663}                         ] 47% 5.15s
{0, 4.8006} -> {0, 4.69746}>                         ] 48% 5.242s
{0, 6.02894} -> {0, 5.81699}                         ] 49% 5.333s
{0, 6.23602} -> {0, 5.63007}>                        ] 50% 5.425s
{0, 8.03881} -> {0, 7.77583}>                        ] 51% 5.518s
{0, 5.99011} -> {0, 5.84972}=>                       ] 52% 5.611s
{0, 11.2678} -> {0, 11.1578}=>                       ] 53% 5.704s
{0, 8.03881} -> {0, 7.00649}=>                       ] 53% 5.794s
{0, 9.68039} -> {0, 9.47241}==>                      ] 54% 5.885s
{0, 6.7725} -> {0, 6.58732}===>                      ] 55% 5.993s
{0, 8.21897} -> {0, 7.79357}===>                     ] 56% 6.092s
{0, 7.46627} -> {0, 7.12723}===>                     ] 57% 6.183s
{0, 6.67027} -> {0, 6.39017}====>                    ] 58% 6.275s
{0, 6.42045} -> {0, 6.12889}====>                    ] 59% 6.367s
{0, 8.21379} -> {0, 7.81273}=====>                   ] 60% 6.458s
{0, 5.34708} -> {0, 5.10427}=====>                   ] 61% 6.55s
{0, 7.76536} -> {0, 7.58715}=====>                   ] 61% 6.641s
{0, 6.23602} -> {0, 5.63007}======>                  ] 62% 6.731s
{0, 7.98408} -> {0, 7.73848}======>                  ] 63% 6.819s
{0, 7.94185} -> {0, 7.22833}=======>                 ] 64% 6.91s
{0, 9.17409} -> {0, 8.96356}=======>                 ] 65% 7.003s
{0, 6.38295} -> {0, 6.27698}========>                ] 66% 7.111s
{0, 7.70094} -> {0, 7.63325}========>                ] 67% 7.203s
{0, 8.90911} -> {0, 8.64375}=========>               ] 68% 7.294s
{0, 8.90911} -> {0, 7.76502}=========>               ] 69% 7.384s
{0, 5.08739} -> {0, 4.93089}=========>               ] 69% 7.476s
{0, 5.61846} -> {0, 5.13288}==========>              ] 70% 7.566s
{0, 4.93296} -> {0, 4.92333}==========>              ] 71% 7.657s
{0, 6.6802} -> {0, 6.10286}============>             ] 72% 7.752s
{0, 6.70045} -> {0, 6.6252}============>             ] 73% 7.844s
{0, 5.81036} -> {0, 5.2855}=============>            ] 74% 7.937s
{0, 5.05064} -> {0, 4.80156}============>            ] 75% 8.03s
{0, 5.05064} -> {0, 4.80156}=============>           ] 76% 8.135s
{0, 10.5383} -> {0, 10.4045}=============>           ] 76% 8.225s
{0, 7.19098} -> {0, 6.93817}=============>           ] 77% 8.317s
{0, 5.47594} -> {0, 5.31284}==============>          ] 78% 8.406s
{0, 8.95441} -> {0, 8.70081}==============>          ] 79% 8.5s
{0, 8.95441} -> {0, 8.198}=================>         ] 80% 8.593s
{0, 5.52642} -> {0, 5.09197}===============>         ] 81% 8.684s
{0, 5.18016} -> {0, 4.83616}================>        ] 82% 8.776s
{0, 5.58032} -> {0, 5.5231}=================>        ] 83% 8.866s
{0, 7.42506} -> {0, 7.21116}=================>       ] 84% 8.958s
{0, 5.11194} -> {0, 4.97715}=================>       ] 84% 9.051s
{0, 5.18716} -> {0, 4.92628}=================>       ] 85% 9.153s
{0, 7.94185} -> {0, 7.10036}==================>      ] 86% 9.244s
{0, 2.93711} -> {0, 2.7435}===================>      ] 87% 9.337s
{0, 5.52642} -> {0, 4.98943}===================>     ] 88% 9.427s
{0, 5.42753} -> {0, 5.30297}===================>     ] 89% 9.518s
{0, 5.54847} -> {0, 5.47532}====================>    ] 90% 9.609s
{0, 10.4949} -> {0, 10.167}=====================>    ] 91% 9.7s
{0, 6.69615} -> {0, 6.56536}=====================>   ] 92% 9.792s
{0, 9.68039} -> {0, 8.43725}=====================>   ] 92% 9.885s
{0, 9.41811} -> {0, 9.20197}=====================>   ] 93% 9.982s
{0, 9.41811} -> {0, 9.20197}======================>  ] 94% 10.079s
{0, 0.0673623} -> {0, 0.0673623}==================>  ] 95% 10.236s
{0, 0.01} -> {0, 0.01}=============================> ] 96% 10.329s
{0, 2.28979} -> {0, 2.24283}=======================> ] 97% 10.421s
{0, 3.03497} -> {0, 2.9505}=========================>] 98% 10.511s
{-55.297, 53.387} -> {-51.2107, 50.7867}============>] 99% 10.603s
  [==================================================] 100% 64.559s
  4.5. Quantize graph...
WARN: Conv2D_2 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_9 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_20 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_26 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_33 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_44 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_50 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_56 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_62 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_35 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_68 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_73 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_74 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_11 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_80 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_86 Fallback to float conv2d due to weights divergence.
5. Lowering...
6. Optimize Pass 3...
7. Generate code...
  Plan buffers...
  Emit code...
Working memory usage: 353280 B

SUMMARY
INPUTS
0       input_1 1x3x32x32
OUTPUTS
0       Identity        1x5x32x32

.\ncc.exe compile Model_V0_1.tflite Model_V0_1.kmodel -i tflite -o kmodel --dataset ./data/JPEGImages_Sample/ --dataset-format image --inference-type uint8 --input-mean 0 --input-std 1 --dump-ir --input-type uint8 --max-allocator-solve-secs 120 --calibrate-method l2 --dump-weights-range --weights-quantize-threshold 128 --output-quantize-threshold 1000
1. Import graph...
2. Optimize Pass 1...
Dump weights range ...
Conv2D_0{-7.69981, 5.65006}
Conv2D_3{-1.20796, 1.27813}
Conv2D_4{-0.778667, 0.827375}
Conv2D_5{-2.01471, 1.77771}
Conv2D_6{-0.421971, 0.841585}
Conv2D_7{-0.719524, 0.5067}
Conv2D_12{-0.604414, 0.764012}
Conv2D_13{-0.690024, 0.857043}
Conv2D_14{-1.06358, 1.38815}
Conv2D_15{-1.23217, 1.54182}
Conv2D_16{-0.545631, 0.547883}
Conv2D_17{-2.25043, 0.942201}
Conv2D_18{-0.412925, 0.524094}
Conv2D_21{-0.659724, 0.648631}
Conv2D_22{-0.897048, 0.812928}
Conv2D_23{-0.413057, 0.535818}
Conv2D_24{-0.74034, 0.598373}
Conv2D_27{-0.587591, 0.627704}
Conv2D_28{-0.83368, 0.817675}
Conv2D_29{-0.471071, 0.345599}
Conv2D_30{-0.455182, 0.429017}
Conv2D_31{-0.450613, 0.443387}
Conv2D_36{-0.631094, 0.615425}
Conv2D_37{-0.716845, 0.864594}
Conv2D_38{-0.731777, 0.872114}
Conv2D_39{-0.864499, 1.04279}
Conv2D_40{-0.321136, 0.294978}
Conv2D_41{-0.389408, 0.618573}
Conv2D_42{-0.463768, 0.434249}
Conv2D_45{-0.628029, 0.606052}
Conv2D_46{-0.857071, 0.743852}
Conv2D_47{-0.326795, 0.319491}
Conv2D_48{-0.34, 0.583243}
Conv2D_51{-0.639259, 0.782657}
Conv2D_52{-0.792057, 0.785551}
Conv2D_53{-0.375116, 0.291687}
Conv2D_54{-0.428019, 0.417399}
Conv2D_57{-0.864689, 0.800644}
Conv2D_58{-1.12123, 0.860939}
Conv2D_59{-0.416292, 0.347888}
Conv2D_60{-0.357286, 0.383075}
Conv2D_63{-0.967548, 0.958137}
Conv2D_64{-1.25436, 1.52667}
Conv2D_65{-0.290778, 0.240788}
Conv2D_66{-0.576748, 0.549428}
Conv2D_69{-0.59016, 1.03322}
Conv2D_70{-1.12056, 0.968841}
Conv2D_71{-0.612557, 0.491848}
Conv2D_72{-1.0838, 0.808319}
Conv2D_75{-1.17118, 1.54664}
Conv2D_76{-2.04342, 7.5335}
Conv2D_77{-0.703412, 0.894966}
Conv2D_78{-1.09949, 0.698665}
Conv2D_81{-1.68518, 2.37004}
Conv2D_82{-0.987302, 1.36442}
Conv2D_83{-0.821405, 0.529464}
Conv2D_84{-1.40452, 0.955955}
Conv2D_87{9.63886, 9.63886}
Conv2D_88{-2.16083, 1.17549e-38}
Conv2D_89{-9.00428, 4.28854}
Conv2D_1{-2.07445, 2.97643}
Conv2D_2{-0.814324, 2.10761}
Conv2D_8{-1.70549, 1.33728}
Conv2D_9{-1.00268, 1.23354}
Conv2D_19{-1.24083, 1.69613}
Conv2D_20{-0.968029, 1.10703}
Conv2D_25{-1.57136, 1.99744}
Conv2D_26{-1.276, 1.15703}
Conv2D_32{-2.44768, 2.68878}
Conv2D_33{-1.91571, 2.17723}
Conv2D_43{-1.63416, 6.87644}
Conv2D_44{-2.39985, 2.38712}
Conv2D_49{-4.55612, 9.03819}
Conv2D_50{-5.61178, 20.7805}
Conv2D_55{-2.23221, 2.68983}
Conv2D_56{-1.31554, 1.76325}
Conv2D_61{-2.53103, 10.576}
Conv2D_62{-9.62121, 9.81594}
Conv2D_34{-1.33452, 1.98011}
Conv2D_35{-1.18227, 1.51693}
Conv2D_67{-12.4833, 18.4161}
Conv2D_68{-6.76074, 6.29711}
Conv2D_73{-15.2925, 25.2836}
Conv2D_74{-33.6843, 27.6947}
Conv2D_10{-1.87758, 1.64303}
Conv2D_11{-0.869822, 1.2687}
Conv2D_79{-1.52001, 2.16186}
Conv2D_80{-1.46659, 2.8314}
Conv2D_85{0.00839139, 0.0886092}
Conv2D_86{-0.0923645, 0.481875}
3. Optimize Pass 2...
4. Quantize...
  4.1. Add quantization checkpoints...
  4.2. Get activation ranges...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.826s
  4.3. Get activation distributions...
  Plan buffers...
  Run calibration...
  [==================================================] 100% 3.628s
  4.4. Find optimal thresholds...
{0, 4.86935} -> {0, 4.24404}                         ] 0% 0s
{0, 6.7725} -> {0, 6.58732}                          ] 0% 0.099s
{0, 5.81036} -> {0, 5.6146}                          ] 1% 0.218s
{0, 7.96055} -> {0, 7.52521}                         ] 2% 0.311s
{0, 7.94185} -> {0, 6.92198}                         ] 3% 0.408s
{0, 8.43533} -> {0, 7.71042}                         ] 4% 0.503s
{0, 6.85896} -> {0, 5.97815}                         ] 5% 0.597s
{0, 6.85896} -> {0, 6.20589}                         ] 6% 0.693s
{0, 4.87661} -> {0, 4.68611}                         ] 7% 0.788s
{0, 7.62872} -> {0, 6.64906}                         ] 7% 0.884s
{0, 8.90911} -> {0, 8.64375}                         ] 8% 0.99s
{0, 6.80435} -> {0, 6.3525}                          ] 9% 1.084s
{0, 12.5055} -> {0, 11.4674}                         ] 10% 1.179s
{0, 11.2678} -> {0, 11.1578}                         ] 11% 1.292s
{0, 7.94185} -> {0, 7.22833}                         ] 12% 1.386s
{0, 8.74409} -> {0, 6.89536}                         ] 13% 1.479s
{0, 6.23602} -> {0, 5.63007}                         ] 14% 1.572s
{0, 8.48414} -> {0, 7.92488}                         ] 15% 1.666s
{0, 8.101} -> {0, 7.06069}                           ] 15% 1.761s
{0, 7.58859} -> {0, 7.27734}                         ] 16% 1.855s
{0, 9.10347} -> {0, 8.41004}                         ] 17% 1.95s
{0, 7.43552} -> {0, 6.66946}                         ] 18% 2.046s
{0, 6.69615} -> {0, 6.56536}                         ] 19% 2.141s
{0, 5.14937} -> {0, 4.64901}                         ] 20% 2.237s
{0, 6.6166} -> {0, 6.25152}                          ] 21% 2.35s
{0, 7.94185} -> {0, 6.92198}                         ] 22% 2.451s
{0, 6.5187} -> {0, 5.98078}                          ] 23% 2.556s
{0, 8.101} -> {0, 7.06069}                           ] 23% 2.651s
{0, 7.62972} -> {0, 6.64993}                         ] 24% 2.746s
{0, 7.69642} -> {0, 7.26425}                         ] 25% 2.84s
{0, 5.15102} -> {0, 4.70835}                         ] 26% 2.935s
{0, 10.7851} -> {0, 10.4744}                         ] 27% 3.034s
{0, 6.82579} -> {0, 6.63581}                         ] 28% 3.131s
{0, 5.53839} -> {0, 5.26255}                         ] 29% 3.226s
{0, 5.58032} -> {0, 5.5231}                          ] 30% 3.335s
{0, 8.74409} -> {0, 7.62119}                         ] 30% 3.43s
{0, 9.56657} -> {0, 8.93129}                         ] 31% 3.524s
{0, 10.8683} -> {0, 9.4726}                          ] 32% 3.618s
{0, 11.6405} -> {0, 11.1119}                         ] 33% 3.713s
{0, 5.99011} -> {0, 5.84972}                         ] 34% 3.812s
{0, 6.31197} -> {0, 5.5014}                          ] 35% 3.905s
{0, 6.23602} -> {0, 5.4352}                          ] 36% 4.001s
{0, 5.18016} -> {0, 4.83616}                         ] 37% 4.094s
{0, 6.23602} -> {0, 5.63007}                         ] 38% 4.188s
{0, 8.21897} -> {0, 7.79357}                         ] 38% 4.283s
{0, 6.67726} -> {0, 6.55663}                         ] 39% 4.396s
{0, 5.34708} -> {0, 5.10427}                         ] 40% 4.489s
{0, 4.8006} -> {0, 4.69746}                          ] 41% 4.587s
{0, 11.5465} -> {0, 11.0221}                         ] 42% 4.679s
{0, 7.14744} -> {0, 6.89617}                         ] 43% 4.803s
{0, 8.95441} -> {0, 8.198}                           ] 44% 4.897s
{0, 6.02894} -> {0, 5.81699}                         ] 45% 4.99s
{0, 6.24038} -> {0, 6.02099}                         ] 46% 5.086s
{0, 7.77231} -> {0, 7.57117}                         ] 46% 5.181s
{0, 9.40854} -> {0, 9.02724}                         ] 47% 5.275s
{0, 6.49012} -> {0, 6.23026}                         ] 48% 5.378s
{0, 8.03881} -> {0, 7.77583}                         ] 49% 5.497s
{0, 8.03881} -> {0, 7.00649}>                        ] 50% 5.634s
{0, 7.46627} -> {0, 7.12723}>                        ] 51% 5.776s
{0, 9.15786} -> {0, 8.742}===>                       ] 52% 5.914s
{0, 8.21379} -> {0, 7.81273}=>                       ] 53% 6.013s
{0, 6.67027} -> {0, 6.39017}=>                       ] 53% 6.107s
{0, 8.43533} -> {0, 7.35209}==>                      ] 54% 6.204s
{0, 9.22257} -> {0, 8.80377}==>                      ] 55% 6.301s
{0, 6.42045} -> {0, 6.12889}===>                     ] 56% 6.394s
{0, 8.21379} -> {0, 7.15899}===>                     ] 57% 6.502s
{0, 7.17185} -> {0, 7.05629}====>                    ] 58% 6.599s
{0, 6.45081} -> {0, 6.45081}====>                    ] 59% 6.696s
{0, 7.76536} -> {0, 7.58715}=====>                   ] 60% 6.79s
{0, 5.11194} -> {0, 4.97715}=====>                   ] 61% 6.884s
{0, 7.76536} -> {0, 7.04494}=====>                   ] 61% 6.98s
{0, 5.61846} -> {0, 5.30846}======>                  ] 62% 7.072s
{0, 5.47594} -> {0, 5.31284}======>                  ] 63% 7.168s
{0, 6.23602} -> {0, 5.63007}=======>                 ] 64% 7.266s
{0, 9.01326} -> {0, 8.78881}=======>                 ] 65% 7.362s
{0, 7.98408} -> {0, 7.73848}========>                ] 66% 7.46s
{0, 9.17409} -> {0, 8.96356}========>                ] 67% 7.572s
{0, 6.38295} -> {0, 6.27698}=========>               ] 68% 7.667s
{0, 7.70094} -> {0, 7.63325}=========>               ] 69% 7.759s
{0, 8.90911} -> {0, 7.76502}=========>               ] 69% 7.854s
{0, 5.08739} -> {0, 4.93089}==========>              ] 70% 7.953s
{0, 0.01} -> {0, 0.01}================>              ] 71% 8.047s
{0, 5.61846} -> {0, 5.13288}===========>             ] 72% 8.148s
{0, 7.78294} -> {0, 7.57773}===========>             ] 73% 8.243s
{0, 4.93296} -> {0, 4.92333}============>            ] 74% 8.341s
{0, 6.70045} -> {0, 6.6252}=============>            ] 75% 8.45s
{0, 5.81036} -> {0, 5.2855}==============>           ] 76% 8.558s
{0, 5.05064} -> {0, 4.80156}=============>           ] 76% 8.653s
{0, 5.05064} -> {0, 4.80156}=============>           ] 77% 8.751s
{0, 10.5383} -> {0, 10.4045}==============>          ] 78% 8.845s
{0, 6.6802} -> {0, 6.10286}===============>          ] 79% 8.941s
{0, 7.19098} -> {0, 6.93817}===============>         ] 80% 9.038s
{0, 8.95441} -> {0, 8.70081}===============>         ] 81% 9.135s
{0, 5.52642} -> {0, 5.09197}================>        ] 82% 9.234s
{0, 7.94185} -> {0, 7.22833}================>        ] 83% 9.329s
{0, 7.42506} -> {0, 7.21116}=================>       ] 84% 9.423s
{0, 5.18716} -> {0, 4.92628}=================>       ] 84% 9.518s
{0, 7.94185} -> {0, 7.10036}=================>       ] 85% 9.625s
{0, 2.93711} -> {0, 2.7435}===================>      ] 86% 9.719s
{0, 5.52642} -> {0, 4.98943}==================>      ] 87% 9.815s
{0, 5.42753} -> {0, 5.30297}===================>     ] 88% 9.909s
{0, 5.54847} -> {0, 5.47532}===================>     ] 89% 10.002s
{0, 9.68039} -> {0, 9.47241}====================>    ] 90% 10.098s
{0, 10.4949} -> {0, 10.167}=====================>    ] 91% 10.191s
{0, 9.68039} -> {0, 8.43725}=====================>   ] 92% 10.293s
{0, 9.41811} -> {0, 9.20197}=====================>   ] 92% 10.387s
{0, 9.41811} -> {0, 9.20197}=====================>   ] 93% 10.484s
{0, 4.14825} -> {0, 4.14825}======================>  ] 94% 10.579s
{0, 0.0673623} -> {0, 0.0673623}==================>  ] 95% 10.689s
{0, 2.28979} -> {0, 2.24283}=======================> ] 96% 10.782s
{0, 3.03497} -> {0, 2.9505}========================> ] 97% 10.876s
{0, 9.41811} -> {0, 9.03182}========================>] 98% 10.973s
{-55.297, 53.387} -> {-51.2107, 50.7867}============>] 99% 11.072s
  [==================================================] 100% 69.069s
  4.5. Quantize graph...
WARN: Conv2D_2 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_9 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_20 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_26 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_33 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_44 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_50 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_56 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_62 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_35 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_68 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_74 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_11 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_80 Fallback to float conv2d due to weights divergence.
WARN: Conv2D_86 Fallback to float conv2d due to weights divergence.
5. Lowering...
6. Optimize Pass 3...
7. Generate code...
  Plan buffers...
  Emit code...
Working memory usage: 362496 B

SUMMARY
INPUTS
0       input_1 1x3x32x32
OUTPUTS
0       Identity        1x5x32x32
